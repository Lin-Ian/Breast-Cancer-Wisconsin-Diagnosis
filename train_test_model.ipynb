{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:26.743901900Z",
     "start_time": "2023-08-01T00:55:26.689126600Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0         M        17.99         10.38          122.80     1001.0   \n1         M        20.57         17.77          132.90     1326.0   \n2         M        19.69         21.25          130.00     1203.0   \n3         M        11.42         20.38           77.58      386.1   \n4         M        20.29         14.34          135.10     1297.0   \n\n   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0          0.11840           0.27760          0.3001              0.14710   \n1          0.08474           0.07864          0.0869              0.07017   \n2          0.10960           0.15990          0.1974              0.12790   \n3          0.14250           0.28390          0.2414              0.10520   \n4          0.10030           0.13280          0.1980              0.10430   \n\n   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n0         0.2419  ...         25.38          17.33           184.60   \n1         0.1812  ...         24.99          23.41           158.80   \n2         0.2069  ...         23.57          25.53           152.50   \n3         0.2597  ...         14.91          26.50            98.87   \n4         0.1809  ...         22.54          16.67           152.20   \n\n   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n0      2019.0            0.1622             0.6656           0.7119   \n1      1956.0            0.1238             0.1866           0.2416   \n2      1709.0            0.1444             0.4245           0.4504   \n3       567.7            0.2098             0.8663           0.6869   \n4      1575.0            0.1374             0.2050           0.4000   \n\n   concave points_worst  symmetry_worst  fractal_dimension_worst  \n0                0.2654          0.4601                  0.11890  \n1                0.1860          0.2750                  0.08902  \n2                0.2430          0.3613                  0.08758  \n3                0.2575          0.6638                  0.17300  \n4                0.1625          0.2364                  0.07678  \n\n[5 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>...</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/cleaned_data.csv')\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:26.771648400Z",
     "start_time": "2023-08-01T00:55:26.745894300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "x = data.drop(['diagnosis'], axis=1)\n",
    "y = data['diagnosis']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:26.784610400Z",
     "start_time": "2023-08-01T00:55:26.769324500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:26.898023700Z",
     "start_time": "2023-08-01T00:55:26.774633900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "((455, 30), (114, 30), (455,), (114,))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:26.923663900Z",
     "start_time": "2023-08-01T00:55:26.899020400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:26.924588600Z",
     "start_time": "2023-08-01T00:55:26.906140700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n0     0.521037      0.370308        0.511437   0.359788         0.460143   \n1     0.629893      0.156578        0.630986   0.489290         0.430351   \n2     0.095556      0.158607        0.086863   0.043606         0.157263   \n3     0.247480      0.148123        0.241794   0.135101         0.256838   \n4     0.253632      0.177207        0.238408   0.138112         0.308658   \n5     0.372900      0.244505        0.353120   0.224899         0.330505   \n6     0.310426      0.157254        0.301776   0.179343         0.407692   \n7     0.610961      0.356781        0.599198   0.454083         0.461045   \n8     0.642198      0.377071        0.649644   0.493955         0.469170   \n9     0.237068      0.513358        0.233709   0.126320         0.454726   \n\n   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n0          0.340531        0.281396             0.438569       0.470707   \n1          0.347893        0.463918             0.518390       0.378283   \n2          0.036133        0.008625             0.017256       0.367677   \n3          0.180510        0.160239             0.125944       0.295960   \n4          0.080762        0.049414             0.102087       0.258081   \n5          0.157536        0.078397             0.142992       0.259091   \n6          0.189896        0.156139             0.237624       0.416667   \n7          0.342372        0.330600             0.468738       0.374747   \n8          0.473959        0.488519             0.657058       0.538889   \n9          0.223299        0.127484             0.212425       0.383838   \n\n   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n0                0.229620  ...      0.467805       0.356876         0.436725   \n1                0.188750  ...      0.519744       0.123934         0.506948   \n2                0.397495  ...      0.062931       0.214552         0.052244   \n3                0.248297  ...      0.184988       0.193763         0.185467   \n4                0.150297  ...      0.186766       0.128731         0.167837   \n5                0.149198  ...      0.298115       0.227079         0.258429   \n6                0.163041  ...      0.255425       0.192964         0.245480   \n7                0.255768  ...      0.562078       0.352079         0.548284   \n8                0.269611  ...      0.582355       0.358742         0.546790   \n9                0.401230  ...      0.179651       0.488806         0.169680   \n\n   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n0    0.286030          0.508684           0.380196         0.282137   \n1    0.341575          0.437364           0.195155         0.341880   \n2    0.024651          0.181206           0.027487         0.012581   \n3    0.084718          0.207555           0.236995         0.262906   \n4    0.085504          0.222083           0.044091         0.042060   \n5    0.145571          0.334346           0.140247         0.104274   \n6    0.129276          0.480948           0.164736         0.204274   \n7    0.359025          0.465760           0.333414         0.357692   \n8    0.399086          0.367364           0.314306         0.378889   \n9    0.080785          0.395760           0.170117         0.137521   \n\n   concave points_worst  symmetry_worst  fractal_dimension_worst  \n0              0.678351        0.355038                 0.319306  \n1              0.558419        0.189639                 0.230967  \n2              0.047732        0.338641                 0.244459  \n3              0.314089        0.264021                 0.353678  \n4              0.164708        0.173954                 0.048506  \n5              0.273918        0.227899                 0.139844  \n6              0.442612        0.335314                 0.186101  \n7              0.554296        0.233603                 0.387086  \n8              0.738144        0.359078                 0.219295  \n9              0.413058        0.245485                 0.292323  \n\n[10 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>fractal_dimension_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.521037</td>\n      <td>0.370308</td>\n      <td>0.511437</td>\n      <td>0.359788</td>\n      <td>0.460143</td>\n      <td>0.340531</td>\n      <td>0.281396</td>\n      <td>0.438569</td>\n      <td>0.470707</td>\n      <td>0.229620</td>\n      <td>...</td>\n      <td>0.467805</td>\n      <td>0.356876</td>\n      <td>0.436725</td>\n      <td>0.286030</td>\n      <td>0.508684</td>\n      <td>0.380196</td>\n      <td>0.282137</td>\n      <td>0.678351</td>\n      <td>0.355038</td>\n      <td>0.319306</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.629893</td>\n      <td>0.156578</td>\n      <td>0.630986</td>\n      <td>0.489290</td>\n      <td>0.430351</td>\n      <td>0.347893</td>\n      <td>0.463918</td>\n      <td>0.518390</td>\n      <td>0.378283</td>\n      <td>0.188750</td>\n      <td>...</td>\n      <td>0.519744</td>\n      <td>0.123934</td>\n      <td>0.506948</td>\n      <td>0.341575</td>\n      <td>0.437364</td>\n      <td>0.195155</td>\n      <td>0.341880</td>\n      <td>0.558419</td>\n      <td>0.189639</td>\n      <td>0.230967</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.095556</td>\n      <td>0.158607</td>\n      <td>0.086863</td>\n      <td>0.043606</td>\n      <td>0.157263</td>\n      <td>0.036133</td>\n      <td>0.008625</td>\n      <td>0.017256</td>\n      <td>0.367677</td>\n      <td>0.397495</td>\n      <td>...</td>\n      <td>0.062931</td>\n      <td>0.214552</td>\n      <td>0.052244</td>\n      <td>0.024651</td>\n      <td>0.181206</td>\n      <td>0.027487</td>\n      <td>0.012581</td>\n      <td>0.047732</td>\n      <td>0.338641</td>\n      <td>0.244459</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.247480</td>\n      <td>0.148123</td>\n      <td>0.241794</td>\n      <td>0.135101</td>\n      <td>0.256838</td>\n      <td>0.180510</td>\n      <td>0.160239</td>\n      <td>0.125944</td>\n      <td>0.295960</td>\n      <td>0.248297</td>\n      <td>...</td>\n      <td>0.184988</td>\n      <td>0.193763</td>\n      <td>0.185467</td>\n      <td>0.084718</td>\n      <td>0.207555</td>\n      <td>0.236995</td>\n      <td>0.262906</td>\n      <td>0.314089</td>\n      <td>0.264021</td>\n      <td>0.353678</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.253632</td>\n      <td>0.177207</td>\n      <td>0.238408</td>\n      <td>0.138112</td>\n      <td>0.308658</td>\n      <td>0.080762</td>\n      <td>0.049414</td>\n      <td>0.102087</td>\n      <td>0.258081</td>\n      <td>0.150297</td>\n      <td>...</td>\n      <td>0.186766</td>\n      <td>0.128731</td>\n      <td>0.167837</td>\n      <td>0.085504</td>\n      <td>0.222083</td>\n      <td>0.044091</td>\n      <td>0.042060</td>\n      <td>0.164708</td>\n      <td>0.173954</td>\n      <td>0.048506</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.372900</td>\n      <td>0.244505</td>\n      <td>0.353120</td>\n      <td>0.224899</td>\n      <td>0.330505</td>\n      <td>0.157536</td>\n      <td>0.078397</td>\n      <td>0.142992</td>\n      <td>0.259091</td>\n      <td>0.149198</td>\n      <td>...</td>\n      <td>0.298115</td>\n      <td>0.227079</td>\n      <td>0.258429</td>\n      <td>0.145571</td>\n      <td>0.334346</td>\n      <td>0.140247</td>\n      <td>0.104274</td>\n      <td>0.273918</td>\n      <td>0.227899</td>\n      <td>0.139844</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.310426</td>\n      <td>0.157254</td>\n      <td>0.301776</td>\n      <td>0.179343</td>\n      <td>0.407692</td>\n      <td>0.189896</td>\n      <td>0.156139</td>\n      <td>0.237624</td>\n      <td>0.416667</td>\n      <td>0.163041</td>\n      <td>...</td>\n      <td>0.255425</td>\n      <td>0.192964</td>\n      <td>0.245480</td>\n      <td>0.129276</td>\n      <td>0.480948</td>\n      <td>0.164736</td>\n      <td>0.204274</td>\n      <td>0.442612</td>\n      <td>0.335314</td>\n      <td>0.186101</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.610961</td>\n      <td>0.356781</td>\n      <td>0.599198</td>\n      <td>0.454083</td>\n      <td>0.461045</td>\n      <td>0.342372</td>\n      <td>0.330600</td>\n      <td>0.468738</td>\n      <td>0.374747</td>\n      <td>0.255768</td>\n      <td>...</td>\n      <td>0.562078</td>\n      <td>0.352079</td>\n      <td>0.548284</td>\n      <td>0.359025</td>\n      <td>0.465760</td>\n      <td>0.333414</td>\n      <td>0.357692</td>\n      <td>0.554296</td>\n      <td>0.233603</td>\n      <td>0.387086</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.642198</td>\n      <td>0.377071</td>\n      <td>0.649644</td>\n      <td>0.493955</td>\n      <td>0.469170</td>\n      <td>0.473959</td>\n      <td>0.488519</td>\n      <td>0.657058</td>\n      <td>0.538889</td>\n      <td>0.269611</td>\n      <td>...</td>\n      <td>0.582355</td>\n      <td>0.358742</td>\n      <td>0.546790</td>\n      <td>0.399086</td>\n      <td>0.367364</td>\n      <td>0.314306</td>\n      <td>0.378889</td>\n      <td>0.738144</td>\n      <td>0.359078</td>\n      <td>0.219295</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.237068</td>\n      <td>0.513358</td>\n      <td>0.233709</td>\n      <td>0.126320</td>\n      <td>0.454726</td>\n      <td>0.223299</td>\n      <td>0.127484</td>\n      <td>0.212425</td>\n      <td>0.383838</td>\n      <td>0.401230</td>\n      <td>...</td>\n      <td>0.179651</td>\n      <td>0.488806</td>\n      <td>0.169680</td>\n      <td>0.080785</td>\n      <td>0.395760</td>\n      <td>0.170117</td>\n      <td>0.137521</td>\n      <td>0.413058</td>\n      <td>0.245485</td>\n      <td>0.292323</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_columns = x.columns\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_train_scaled = min_max_scaler.fit_transform(x_train)\n",
    "x_train_scaled = pd.DataFrame(x_train_scaled, columns=x_columns)\n",
    "x_train_scaled.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:26.956407400Z",
     "start_time": "2023-08-01T00:55:26.908641600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n0     0.364854      0.144403        0.376132   0.217434         0.455629   \n1     0.292915      0.302672        0.291549   0.165896         0.570281   \n2     0.282503      0.213392        0.271923   0.157031         0.432157   \n3     0.536182      0.299966        0.516965   0.380700         0.300172   \n4     0.385678      0.679743        0.365697   0.244327         0.275977   \n5     0.434427      0.400068        0.431276   0.282630         0.434865   \n6     0.577831      0.210687        0.570175   0.429905         0.309741   \n7     0.525297      0.410213        0.508673   0.373489         0.190304   \n8     0.165602      0.343253        0.158455   0.082375         0.490837   \n9     0.357281      0.144403        0.346002   0.212386         0.517017   \n\n   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n0          0.503711        0.339738             0.313121       0.518182   \n1          0.318140        0.287254             0.364811       0.539394   \n2          0.184191        0.144213             0.167495       0.338384   \n3          0.200294        0.191401             0.288966       0.283333   \n4          0.081805        0.109794             0.136133       0.400000   \n5          0.334397        0.244377             0.278976       0.555556   \n6          0.304030        0.279522             0.480467       0.343939   \n7          0.205632        0.258435             0.287177       0.358586   \n8          0.123704        0.113191             0.152584       0.341919   \n9          0.224035        0.161551             0.322813       0.297980   \n\n   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n0                0.523401  ...      0.303451       0.168443         0.317197   \n1                0.385190  ...      0.275347       0.424574         0.260919   \n2                0.317732  ...      0.206688       0.210821         0.191245   \n3                0.088113  ...      0.475987       0.382196         0.442203   \n4                0.059328  ...      0.331910       0.663380         0.297276   \n5                0.190508  ...      0.410530       0.523987         0.394890   \n6                0.033399  ...      0.501601       0.154318         0.479058   \n7                0.069435  ...      0.420847       0.337953         0.391902   \n8                0.311140  ...      0.126290       0.464819         0.115892   \n9                0.241046  ...      0.279972       0.130864         0.262413   \n\n   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n0    0.153362          0.396421           0.369214         0.275128   \n1    0.141123          0.709437           0.427527         0.427863   \n2    0.098358          0.509344           0.197132         0.191538   \n3    0.301022          0.344912           0.238532         0.302393   \n4    0.183396          0.288120           0.078376         0.132222   \n5    0.243266          0.451232           0.305520         0.255726   \n6    0.321913          0.272271           0.191421         0.193504   \n7    0.256292          0.112593           0.185601         0.216667   \n8    0.053480          0.530476           0.082703         0.100940   \n9    0.138788          0.419534           0.132340         0.117350   \n\n   concave points_worst  symmetry_worst  fractal_dimension_worst  \n0              0.380756        0.299667                 0.394796  \n1              0.717526        0.554658                 0.671271  \n2              0.362887        0.431084                 0.435057  \n3              0.539863        0.389734                 0.151729  \n4              0.225945        0.396150                 0.068958  \n5              0.450859        0.454848                 0.224649  \n6              0.610653        0.208413                 0.078167  \n7              0.315498        0.190827                 0.111040  \n8              0.231478        0.312975                 0.238462  \n9              0.367354        0.247148                 0.245101  \n\n[10 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>fractal_dimension_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.364854</td>\n      <td>0.144403</td>\n      <td>0.376132</td>\n      <td>0.217434</td>\n      <td>0.455629</td>\n      <td>0.503711</td>\n      <td>0.339738</td>\n      <td>0.313121</td>\n      <td>0.518182</td>\n      <td>0.523401</td>\n      <td>...</td>\n      <td>0.303451</td>\n      <td>0.168443</td>\n      <td>0.317197</td>\n      <td>0.153362</td>\n      <td>0.396421</td>\n      <td>0.369214</td>\n      <td>0.275128</td>\n      <td>0.380756</td>\n      <td>0.299667</td>\n      <td>0.394796</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.292915</td>\n      <td>0.302672</td>\n      <td>0.291549</td>\n      <td>0.165896</td>\n      <td>0.570281</td>\n      <td>0.318140</td>\n      <td>0.287254</td>\n      <td>0.364811</td>\n      <td>0.539394</td>\n      <td>0.385190</td>\n      <td>...</td>\n      <td>0.275347</td>\n      <td>0.424574</td>\n      <td>0.260919</td>\n      <td>0.141123</td>\n      <td>0.709437</td>\n      <td>0.427527</td>\n      <td>0.427863</td>\n      <td>0.717526</td>\n      <td>0.554658</td>\n      <td>0.671271</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.282503</td>\n      <td>0.213392</td>\n      <td>0.271923</td>\n      <td>0.157031</td>\n      <td>0.432157</td>\n      <td>0.184191</td>\n      <td>0.144213</td>\n      <td>0.167495</td>\n      <td>0.338384</td>\n      <td>0.317732</td>\n      <td>...</td>\n      <td>0.206688</td>\n      <td>0.210821</td>\n      <td>0.191245</td>\n      <td>0.098358</td>\n      <td>0.509344</td>\n      <td>0.197132</td>\n      <td>0.191538</td>\n      <td>0.362887</td>\n      <td>0.431084</td>\n      <td>0.435057</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.536182</td>\n      <td>0.299966</td>\n      <td>0.516965</td>\n      <td>0.380700</td>\n      <td>0.300172</td>\n      <td>0.200294</td>\n      <td>0.191401</td>\n      <td>0.288966</td>\n      <td>0.283333</td>\n      <td>0.088113</td>\n      <td>...</td>\n      <td>0.475987</td>\n      <td>0.382196</td>\n      <td>0.442203</td>\n      <td>0.301022</td>\n      <td>0.344912</td>\n      <td>0.238532</td>\n      <td>0.302393</td>\n      <td>0.539863</td>\n      <td>0.389734</td>\n      <td>0.151729</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.385678</td>\n      <td>0.679743</td>\n      <td>0.365697</td>\n      <td>0.244327</td>\n      <td>0.275977</td>\n      <td>0.081805</td>\n      <td>0.109794</td>\n      <td>0.136133</td>\n      <td>0.400000</td>\n      <td>0.059328</td>\n      <td>...</td>\n      <td>0.331910</td>\n      <td>0.663380</td>\n      <td>0.297276</td>\n      <td>0.183396</td>\n      <td>0.288120</td>\n      <td>0.078376</td>\n      <td>0.132222</td>\n      <td>0.225945</td>\n      <td>0.396150</td>\n      <td>0.068958</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.434427</td>\n      <td>0.400068</td>\n      <td>0.431276</td>\n      <td>0.282630</td>\n      <td>0.434865</td>\n      <td>0.334397</td>\n      <td>0.244377</td>\n      <td>0.278976</td>\n      <td>0.555556</td>\n      <td>0.190508</td>\n      <td>...</td>\n      <td>0.410530</td>\n      <td>0.523987</td>\n      <td>0.394890</td>\n      <td>0.243266</td>\n      <td>0.451232</td>\n      <td>0.305520</td>\n      <td>0.255726</td>\n      <td>0.450859</td>\n      <td>0.454848</td>\n      <td>0.224649</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.577831</td>\n      <td>0.210687</td>\n      <td>0.570175</td>\n      <td>0.429905</td>\n      <td>0.309741</td>\n      <td>0.304030</td>\n      <td>0.279522</td>\n      <td>0.480467</td>\n      <td>0.343939</td>\n      <td>0.033399</td>\n      <td>...</td>\n      <td>0.501601</td>\n      <td>0.154318</td>\n      <td>0.479058</td>\n      <td>0.321913</td>\n      <td>0.272271</td>\n      <td>0.191421</td>\n      <td>0.193504</td>\n      <td>0.610653</td>\n      <td>0.208413</td>\n      <td>0.078167</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.525297</td>\n      <td>0.410213</td>\n      <td>0.508673</td>\n      <td>0.373489</td>\n      <td>0.190304</td>\n      <td>0.205632</td>\n      <td>0.258435</td>\n      <td>0.287177</td>\n      <td>0.358586</td>\n      <td>0.069435</td>\n      <td>...</td>\n      <td>0.420847</td>\n      <td>0.337953</td>\n      <td>0.391902</td>\n      <td>0.256292</td>\n      <td>0.112593</td>\n      <td>0.185601</td>\n      <td>0.216667</td>\n      <td>0.315498</td>\n      <td>0.190827</td>\n      <td>0.111040</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.165602</td>\n      <td>0.343253</td>\n      <td>0.158455</td>\n      <td>0.082375</td>\n      <td>0.490837</td>\n      <td>0.123704</td>\n      <td>0.113191</td>\n      <td>0.152584</td>\n      <td>0.341919</td>\n      <td>0.311140</td>\n      <td>...</td>\n      <td>0.126290</td>\n      <td>0.464819</td>\n      <td>0.115892</td>\n      <td>0.053480</td>\n      <td>0.530476</td>\n      <td>0.082703</td>\n      <td>0.100940</td>\n      <td>0.231478</td>\n      <td>0.312975</td>\n      <td>0.238462</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.357281</td>\n      <td>0.144403</td>\n      <td>0.346002</td>\n      <td>0.212386</td>\n      <td>0.517017</td>\n      <td>0.224035</td>\n      <td>0.161551</td>\n      <td>0.322813</td>\n      <td>0.297980</td>\n      <td>0.241046</td>\n      <td>...</td>\n      <td>0.279972</td>\n      <td>0.130864</td>\n      <td>0.262413</td>\n      <td>0.138788</td>\n      <td>0.419534</td>\n      <td>0.132340</td>\n      <td>0.117350</td>\n      <td>0.367354</td>\n      <td>0.247148</td>\n      <td>0.245101</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_scaled = min_max_scaler.transform(x_test)\n",
    "x_test_scaled = pd.DataFrame(x_test_scaled, columns=x_columns)\n",
    "x_test_scaled.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:26.956407400Z",
     "start_time": "2023-08-01T00:55:26.928848400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:26.956407400Z",
     "start_time": "2023-08-01T00:55:26.947438500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:27.133334400Z",
     "start_time": "2023-08-01T00:55:26.949434400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators: 5 / Depth: 5 --- Accuracy: 0.939 / Precision: 1.000 / Recall: 0.833\n",
      "Estimators: 5 / Depth: 10 --- Accuracy: 0.956 / Precision: 0.974 / Recall: 0.905\n",
      "Estimators: 5 / Depth: 20 --- Accuracy: 0.956 / Precision: 0.974 / Recall: 0.905\n",
      "Estimators: 5 / Depth: 30 --- Accuracy: 0.956 / Precision: 0.974 / Recall: 0.905\n",
      "Estimators: 5 / Depth: None --- Accuracy: 0.956 / Precision: 0.974 / Recall: 0.905\n",
      "Estimators: 10 / Depth: 5 --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "Estimators: 10 / Depth: 10 --- Accuracy: 0.956 / Precision: 0.974 / Recall: 0.905\n",
      "Estimators: 10 / Depth: 20 --- Accuracy: 0.956 / Precision: 0.974 / Recall: 0.905\n",
      "Estimators: 10 / Depth: 30 --- Accuracy: 0.956 / Precision: 0.974 / Recall: 0.905\n",
      "Estimators: 10 / Depth: None --- Accuracy: 0.956 / Precision: 0.974 / Recall: 0.905\n",
      "Estimators: 20 / Depth: 5 --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "Estimators: 20 / Depth: 10 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 20 / Depth: 20 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 20 / Depth: 30 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 20 / Depth: None --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 50 / Depth: 5 --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "Estimators: 50 / Depth: 10 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 50 / Depth: 20 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 50 / Depth: 30 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 50 / Depth: None --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 100 / Depth: 5 --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "Estimators: 100 / Depth: 10 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 100 / Depth: 20 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 100 / Depth: 30 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 100 / Depth: None --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n"
     ]
    }
   ],
   "source": [
    "num_est = [5, 10, 20, 50, 100]\n",
    "max_depths = [5, 10, 20, 30, None]\n",
    "\n",
    "for est in num_est:\n",
    "    for depth in max_depths:\n",
    "        rf = RandomForestClassifier(n_estimators=est, max_depth=depth, random_state=1)\n",
    "        rf.fit(x_train_scaled, y_train)\n",
    "        y_pred = rf.predict(x_test_scaled)\n",
    "\n",
    "        accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "        precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "        recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "        print(f'Estimators: {est} / Depth: {depth} --- Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:29.432452500Z",
     "start_time": "2023-08-01T00:55:27.075134400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:29.437432Z",
     "start_time": "2023-08-01T00:55:29.431944200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty: None / C: 0.0001 --- Accuracy: 0.965 / Precision: 0.952 / Recall: 0.952\n",
      "Penalty: None / C: 0.001 --- Accuracy: 0.965 / Precision: 0.952 / Recall: 0.952\n",
      "Penalty: None / C: 0.01 --- Accuracy: 0.965 / Precision: 0.952 / Recall: 0.952\n",
      "Penalty: None / C: 0.1 --- Accuracy: 0.965 / Precision: 0.952 / Recall: 0.952\n",
      "Penalty: None / C: 1 --- Accuracy: 0.965 / Precision: 0.952 / Recall: 0.952\n",
      "Penalty: None / C: 10 --- Accuracy: 0.965 / Precision: 0.952 / Recall: 0.952\n",
      "Penalty: l2 / C: 0.0001 --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Penalty: l2 / C: 0.001 --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Penalty: l2 / C: 0.01 --- Accuracy: 0.728 / Precision: 1.000 / Recall: 0.262\n",
      "Penalty: l2 / C: 0.1 --- Accuracy: 0.921 / Precision: 1.000 / Recall: 0.786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty: l2 / C: 1 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Penalty: l2 / C: 10 --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n"
     ]
    }
   ],
   "source": [
    "penalties = [None, 'l2']\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "for penalty in penalties:\n",
    "    for c_value in C:\n",
    "        lr = LogisticRegression(penalty=penalty, C=c_value)\n",
    "        lr.fit(x_train_scaled, y_train)\n",
    "        y_pred = lr.predict(x_test_scaled)\n",
    "\n",
    "        accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "        precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "        recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "        print(f'Penalty: {penalty} / C: {c_value} --- Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:29.728003700Z",
     "start_time": "2023-08-01T00:55:29.437432Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:29.748926100Z",
     "start_time": "2023-08-01T00:55:29.681018300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.1 / Kernel: linear --- Accuracy: 0.947 / Precision: 1.000 / Recall: 0.857\n",
      "C: 0.1 / Kernel: poly / Degree: 1 --- Accuracy: 0.947 / Precision: 1.000 / Recall: 0.857\n",
      "C: 0.1 / Kernel: poly / Degree: 2 --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "C: 0.1 / Kernel: poly / Degree: 3 --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 0.1 / Kernel: poly / Degree: 4 --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "C: 0.1 / Kernel: poly / Degree: 5 --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 0.1 / Kernel: rbf --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "C: 0.1 / Kernel: sigmoid --- Accuracy: 0.544 / Precision: 0.000 / Recall: 0.000\n",
      "C: 1 / Kernel: linear --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 1 / Kernel: poly / Degree: 1 --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 1 / Kernel: poly / Degree: 2 --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 1 / Kernel: poly / Degree: 3 --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 1 / Kernel: poly / Degree: 4 --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 1 / Kernel: poly / Degree: 5 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "C: 1 / Kernel: rbf --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 1 / Kernel: sigmoid --- Accuracy: 0.316 / Precision: 0.050 / Recall: 0.048\n",
      "C: 10 / Kernel: linear --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 10 / Kernel: poly / Degree: 1 --- Accuracy: 0.965 / Precision: 0.975 / Recall: 0.929\n",
      "C: 10 / Kernel: poly / Degree: 2 --- Accuracy: 0.965 / Precision: 0.975 / Recall: 0.929\n",
      "C: 10 / Kernel: poly / Degree: 3 --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 10 / Kernel: poly / Degree: 4 --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "C: 10 / Kernel: poly / Degree: 5 --- Accuracy: 0.947 / Precision: 1.000 / Recall: 0.857\n",
      "C: 10 / Kernel: rbf --- Accuracy: 0.982 / Precision: 1.000 / Recall: 0.952\n",
      "C: 10 / Kernel: sigmoid --- Accuracy: 0.281 / Precision: 0.045 / Recall: 0.048\n"
     ]
    }
   ],
   "source": [
    "C = [0.1, 1, 10]\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "degrees = [1, 2, 3, 4, 5]\n",
    "\n",
    "for c_value in C:\n",
    "    for kernel in kernels:\n",
    "        if kernel == 'poly':\n",
    "            for degree in degrees:\n",
    "                svc = SVC(C=c_value, kernel=kernel, degree=degree)\n",
    "                svc.fit(x_train_scaled, y_train)\n",
    "                y_pred = svc.predict(x_test_scaled)\n",
    "\n",
    "                accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "                precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "                recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "                print(f'C: {c_value} / Kernel: {kernel} / Degree: {degree} --- Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')\n",
    "        else:\n",
    "            svc = SVC(C=c_value, kernel=kernel)\n",
    "            svc.fit(x_train_scaled, y_train)\n",
    "            y_pred = svc.predict(x_test_scaled)\n",
    "\n",
    "            accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "            precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "            recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "            print(f'C: {c_value} / Kernel: {kernel} --- Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:29.947007300Z",
     "start_time": "2023-08-01T00:55:29.686132200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:29.947007300Z",
     "start_time": "2023-08-01T00:55:29.908242200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors: 2 / Weight: uniform --- Accuracy: 0.939 / Precision: 0.973 / Recall: 0.857\n",
      "Neighbors: 2 / Weight: distance --- Accuracy: 0.930 / Precision: 0.925 / Recall: 0.881\n",
      "Neighbors: 3 / Weight: uniform --- Accuracy: 0.930 / Precision: 0.925 / Recall: 0.881\n",
      "Neighbors: 3 / Weight: distance --- Accuracy: 0.930 / Precision: 0.925 / Recall: 0.881\n",
      "Neighbors: 4 / Weight: uniform --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 4 / Weight: distance --- Accuracy: 0.930 / Precision: 0.925 / Recall: 0.881\n",
      "Neighbors: 5 / Weight: uniform --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 5 / Weight: distance --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 6 / Weight: uniform --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 6 / Weight: distance --- Accuracy: 0.939 / Precision: 0.949 / Recall: 0.881\n",
      "Neighbors: 7 / Weight: uniform --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 7 / Weight: distance --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 8 / Weight: uniform --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 8 / Weight: distance --- Accuracy: 0.939 / Precision: 0.949 / Recall: 0.881\n",
      "Neighbors: 9 / Weight: uniform --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 9 / Weight: distance --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 10 / Weight: uniform --- Accuracy: 0.947 / Precision: 1.000 / Recall: 0.857\n",
      "Neighbors: 10 / Weight: distance --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 11 / Weight: uniform --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Neighbors: 11 / Weight: distance --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Neighbors: 12 / Weight: uniform --- Accuracy: 0.947 / Precision: 1.000 / Recall: 0.857\n",
      "Neighbors: 12 / Weight: distance --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Neighbors: 13 / Weight: uniform --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "Neighbors: 13 / Weight: distance --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "Neighbors: 14 / Weight: uniform --- Accuracy: 0.947 / Precision: 1.000 / Recall: 0.857\n",
      "Neighbors: 14 / Weight: distance --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n"
     ]
    }
   ],
   "source": [
    "max_num_neighbors = 14\n",
    "weights = ['uniform', 'distance']\n",
    "\n",
    "for num_neighbor in range(2, max_num_neighbors+1):\n",
    "    for weight in weights:\n",
    "        knn = KNeighborsClassifier(n_neighbors=num_neighbor, weights=weight)\n",
    "        knn.fit(x_train_scaled.values, y_train)\n",
    "        y_pred = knn.predict(x_test_scaled.values)\n",
    "\n",
    "        accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "        precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "        recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "        print(f'Neighbors: {num_neighbor} / Weight: {weight} --- Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:30.375417800Z",
     "start_time": "2023-08-01T00:55:29.931018Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:30.411715300Z",
     "start_time": "2023-08-01T00:55:30.374421800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: identity / Solver: lbfgs --- Accuracy: 0.974 / Precision: 0.953 / Recall: 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: identity / Solver: sgd --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Hidden Layer Size: 10 / Activation: identity / Solver: adam --- Accuracy: 0.974 / Precision: 0.976 / Recall: 0.952\n",
      "Hidden Layer Size: 10 / Activation: logistic / Solver: lbfgs --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: logistic / Solver: sgd --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: logistic / Solver: adam --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Hidden Layer Size: 10 / Activation: tanh / Solver: lbfgs --- Accuracy: 0.965 / Precision: 0.975 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: tanh / Solver: sgd --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: tanh / Solver: adam --- Accuracy: 0.965 / Precision: 0.975 / Recall: 0.929\n",
      "Hidden Layer Size: 10 / Activation: relu / Solver: lbfgs --- Accuracy: 0.965 / Precision: 0.952 / Recall: 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: relu / Solver: sgd --- Accuracy: 0.702 / Precision: 1.000 / Recall: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: relu / Solver: adam --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 20 / Activation: identity / Solver: lbfgs --- Accuracy: 0.974 / Precision: 0.953 / Recall: 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 20 / Activation: identity / Solver: sgd --- Accuracy: 0.939 / Precision: 0.949 / Recall: 0.881\n",
      "Hidden Layer Size: 20 / Activation: identity / Solver: adam --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "Hidden Layer Size: 20 / Activation: logistic / Solver: lbfgs --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 20 / Activation: logistic / Solver: sgd --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Hidden Layer Size: 20 / Activation: logistic / Solver: adam --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 20 / Activation: tanh / Solver: lbfgs --- Accuracy: 0.982 / Precision: 1.000 / Recall: 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 20 / Activation: tanh / Solver: sgd --- Accuracy: 0.939 / Precision: 0.973 / Recall: 0.857\n",
      "Hidden Layer Size: 20 / Activation: tanh / Solver: adam --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 20 / Activation: relu / Solver: lbfgs --- Accuracy: 0.974 / Precision: 0.976 / Recall: 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 20 / Activation: relu / Solver: sgd --- Accuracy: 0.939 / Precision: 0.973 / Recall: 0.857\n",
      "Hidden Layer Size: 20 / Activation: relu / Solver: adam --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 50 / Activation: identity / Solver: lbfgs --- Accuracy: 0.974 / Precision: 0.953 / Recall: 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 50 / Activation: identity / Solver: sgd --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Hidden Layer Size: 50 / Activation: identity / Solver: adam --- Accuracy: 0.982 / Precision: 1.000 / Recall: 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 50 / Activation: logistic / Solver: lbfgs --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Hidden Layer Size: 50 / Activation: logistic / Solver: sgd --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 50 / Activation: logistic / Solver: adam --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Hidden Layer Size: 50 / Activation: tanh / Solver: lbfgs --- Accuracy: 0.956 / Precision: 0.951 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 50 / Activation: tanh / Solver: sgd --- Accuracy: 0.868 / Precision: 0.886 / Recall: 0.738\n",
      "Hidden Layer Size: 50 / Activation: tanh / Solver: adam --- Accuracy: 0.982 / Precision: 1.000 / Recall: 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 50 / Activation: relu / Solver: lbfgs --- Accuracy: 0.965 / Precision: 0.975 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 50 / Activation: relu / Solver: sgd --- Accuracy: 0.868 / Precision: 0.966 / Recall: 0.667\n",
      "Hidden Layer Size: 50 / Activation: relu / Solver: adam --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100 / Activation: identity / Solver: lbfgs --- Accuracy: 0.974 / Precision: 0.953 / Recall: 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100 / Activation: identity / Solver: sgd --- Accuracy: 0.939 / Precision: 0.949 / Recall: 0.881\n",
      "Hidden Layer Size: 100 / Activation: identity / Solver: adam --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "Hidden Layer Size: 100 / Activation: logistic / Solver: lbfgs --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100 / Activation: logistic / Solver: sgd --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Hidden Layer Size: 100 / Activation: logistic / Solver: adam --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100 / Activation: tanh / Solver: lbfgs --- Accuracy: 0.965 / Precision: 0.975 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100 / Activation: tanh / Solver: sgd --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Hidden Layer Size: 100 / Activation: tanh / Solver: adam --- Accuracy: 0.982 / Precision: 1.000 / Recall: 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100 / Activation: relu / Solver: lbfgs --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100 / Activation: relu / Solver: sgd --- Accuracy: 0.886 / Precision: 0.939 / Recall: 0.738\n",
      "Hidden Layer Size: 100 / Activation: relu / Solver: adam --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_layers = [10, 20, 50, 100]\n",
    "activation_functions = ['identity', 'logistic', 'tanh', 'relu']\n",
    "solvers = ['lbfgs', 'sgd', 'adam']\n",
    "for layers in num_layers:\n",
    "    for activation in activation_functions:\n",
    "        for solver in solvers:\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=num_layers, activation=activation, solver=solver)\n",
    "            mlp.fit(x_train_scaled, y_train)\n",
    "            y_pred = mlp.predict(x_test_scaled)\n",
    "\n",
    "            accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "            precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "            recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "            print(f'Hidden Layer Size: {layers} / Activation: {activation} / Solver: {solver} --- Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:46.247351600Z",
     "start_time": "2023-08-01T00:55:30.384012300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.947 / Precision: 0.950 / Recall: 0.905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train_scaled, y_train)\n",
    "y_pred = nb.predict(x_test_scaled)\n",
    "\n",
    "accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "print(f'Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:46.261055900Z",
     "start_time": "2023-08-01T00:55:46.247351600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.956 / Precision: 0.974 / Recall: 0.905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(x_train_scaled, y_train)\n",
    "y_pred = qda.predict(x_test_scaled)\n",
    "\n",
    "accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "print(f'Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:46.292950400Z",
     "start_time": "2023-08-01T00:55:46.259064100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "gp = GaussianProcessClassifier()\n",
    "gp.fit(x_train_scaled, y_train)\n",
    "y_pred = gp.predict(x_test_scaled)\n",
    "\n",
    "accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "print(f'Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:46.407684500Z",
     "start_time": "2023-08-01T00:55:46.292950400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:46.411683600Z",
     "start_time": "2023-08-01T00:55:46.407684500Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
