{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:27:49.274279200Z",
     "start_time": "2023-08-01T00:27:49.214112700Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0         M        17.99         10.38          122.80     1001.0   \n1         M        20.57         17.77          132.90     1326.0   \n2         M        19.69         21.25          130.00     1203.0   \n3         M        11.42         20.38           77.58      386.1   \n4         M        20.29         14.34          135.10     1297.0   \n\n   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0          0.11840           0.27760          0.3001              0.14710   \n1          0.08474           0.07864          0.0869              0.07017   \n2          0.10960           0.15990          0.1974              0.12790   \n3          0.14250           0.28390          0.2414              0.10520   \n4          0.10030           0.13280          0.1980              0.10430   \n\n   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n0         0.2419  ...         25.38          17.33           184.60   \n1         0.1812  ...         24.99          23.41           158.80   \n2         0.2069  ...         23.57          25.53           152.50   \n3         0.2597  ...         14.91          26.50            98.87   \n4         0.1809  ...         22.54          16.67           152.20   \n\n   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n0      2019.0            0.1622             0.6656           0.7119   \n1      1956.0            0.1238             0.1866           0.2416   \n2      1709.0            0.1444             0.4245           0.4504   \n3       567.7            0.2098             0.8663           0.6869   \n4      1575.0            0.1374             0.2050           0.4000   \n\n   concave points_worst  symmetry_worst  fractal_dimension_worst  \n0                0.2654          0.4601                  0.11890  \n1                0.1860          0.2750                  0.08902  \n2                0.2430          0.3613                  0.08758  \n3                0.2575          0.6638                  0.17300  \n4                0.1625          0.2364                  0.07678  \n\n[5 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>...</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/cleaned_data.csv')\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:27:49.304305600Z",
     "start_time": "2023-08-01T00:27:49.274279200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "x = data.drop(['diagnosis'], axis=1)\n",
    "y = data['diagnosis']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:27:49.324185100Z",
     "start_time": "2023-08-01T00:27:49.304305600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:27:49.454306600Z",
     "start_time": "2023-08-01T00:27:49.314306900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "((455, 30), (114, 30), (455,), (114,))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:27:49.504178600Z",
     "start_time": "2023-08-01T00:27:49.454306600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:27:49.505173800Z",
     "start_time": "2023-08-01T00:27:49.464251100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n0     0.521037      0.370308        0.511437   0.359788         0.460143   \n1     0.629893      0.156578        0.630986   0.489290         0.430351   \n2     0.095556      0.158607        0.086863   0.043606         0.157263   \n3     0.247480      0.148123        0.241794   0.135101         0.256838   \n4     0.253632      0.177207        0.238408   0.138112         0.308658   \n5     0.372900      0.244505        0.353120   0.224899         0.330505   \n6     0.310426      0.157254        0.301776   0.179343         0.407692   \n7     0.610961      0.356781        0.599198   0.454083         0.461045   \n8     0.642198      0.377071        0.649644   0.493955         0.469170   \n9     0.237068      0.513358        0.233709   0.126320         0.454726   \n\n   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n0          0.340531        0.281396             0.438569       0.470707   \n1          0.347893        0.463918             0.518390       0.378283   \n2          0.036133        0.008625             0.017256       0.367677   \n3          0.180510        0.160239             0.125944       0.295960   \n4          0.080762        0.049414             0.102087       0.258081   \n5          0.157536        0.078397             0.142992       0.259091   \n6          0.189896        0.156139             0.237624       0.416667   \n7          0.342372        0.330600             0.468738       0.374747   \n8          0.473959        0.488519             0.657058       0.538889   \n9          0.223299        0.127484             0.212425       0.383838   \n\n   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n0                0.229620  ...      0.467805       0.356876         0.436725   \n1                0.188750  ...      0.519744       0.123934         0.506948   \n2                0.397495  ...      0.062931       0.214552         0.052244   \n3                0.248297  ...      0.184988       0.193763         0.185467   \n4                0.150297  ...      0.186766       0.128731         0.167837   \n5                0.149198  ...      0.298115       0.227079         0.258429   \n6                0.163041  ...      0.255425       0.192964         0.245480   \n7                0.255768  ...      0.562078       0.352079         0.548284   \n8                0.269611  ...      0.582355       0.358742         0.546790   \n9                0.401230  ...      0.179651       0.488806         0.169680   \n\n   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n0    0.286030          0.508684           0.380196         0.282137   \n1    0.341575          0.437364           0.195155         0.341880   \n2    0.024651          0.181206           0.027487         0.012581   \n3    0.084718          0.207555           0.236995         0.262906   \n4    0.085504          0.222083           0.044091         0.042060   \n5    0.145571          0.334346           0.140247         0.104274   \n6    0.129276          0.480948           0.164736         0.204274   \n7    0.359025          0.465760           0.333414         0.357692   \n8    0.399086          0.367364           0.314306         0.378889   \n9    0.080785          0.395760           0.170117         0.137521   \n\n   concave points_worst  symmetry_worst  fractal_dimension_worst  \n0              0.678351        0.355038                 0.319306  \n1              0.558419        0.189639                 0.230967  \n2              0.047732        0.338641                 0.244459  \n3              0.314089        0.264021                 0.353678  \n4              0.164708        0.173954                 0.048506  \n5              0.273918        0.227899                 0.139844  \n6              0.442612        0.335314                 0.186101  \n7              0.554296        0.233603                 0.387086  \n8              0.738144        0.359078                 0.219295  \n9              0.413058        0.245485                 0.292323  \n\n[10 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>fractal_dimension_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.521037</td>\n      <td>0.370308</td>\n      <td>0.511437</td>\n      <td>0.359788</td>\n      <td>0.460143</td>\n      <td>0.340531</td>\n      <td>0.281396</td>\n      <td>0.438569</td>\n      <td>0.470707</td>\n      <td>0.229620</td>\n      <td>...</td>\n      <td>0.467805</td>\n      <td>0.356876</td>\n      <td>0.436725</td>\n      <td>0.286030</td>\n      <td>0.508684</td>\n      <td>0.380196</td>\n      <td>0.282137</td>\n      <td>0.678351</td>\n      <td>0.355038</td>\n      <td>0.319306</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.629893</td>\n      <td>0.156578</td>\n      <td>0.630986</td>\n      <td>0.489290</td>\n      <td>0.430351</td>\n      <td>0.347893</td>\n      <td>0.463918</td>\n      <td>0.518390</td>\n      <td>0.378283</td>\n      <td>0.188750</td>\n      <td>...</td>\n      <td>0.519744</td>\n      <td>0.123934</td>\n      <td>0.506948</td>\n      <td>0.341575</td>\n      <td>0.437364</td>\n      <td>0.195155</td>\n      <td>0.341880</td>\n      <td>0.558419</td>\n      <td>0.189639</td>\n      <td>0.230967</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.095556</td>\n      <td>0.158607</td>\n      <td>0.086863</td>\n      <td>0.043606</td>\n      <td>0.157263</td>\n      <td>0.036133</td>\n      <td>0.008625</td>\n      <td>0.017256</td>\n      <td>0.367677</td>\n      <td>0.397495</td>\n      <td>...</td>\n      <td>0.062931</td>\n      <td>0.214552</td>\n      <td>0.052244</td>\n      <td>0.024651</td>\n      <td>0.181206</td>\n      <td>0.027487</td>\n      <td>0.012581</td>\n      <td>0.047732</td>\n      <td>0.338641</td>\n      <td>0.244459</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.247480</td>\n      <td>0.148123</td>\n      <td>0.241794</td>\n      <td>0.135101</td>\n      <td>0.256838</td>\n      <td>0.180510</td>\n      <td>0.160239</td>\n      <td>0.125944</td>\n      <td>0.295960</td>\n      <td>0.248297</td>\n      <td>...</td>\n      <td>0.184988</td>\n      <td>0.193763</td>\n      <td>0.185467</td>\n      <td>0.084718</td>\n      <td>0.207555</td>\n      <td>0.236995</td>\n      <td>0.262906</td>\n      <td>0.314089</td>\n      <td>0.264021</td>\n      <td>0.353678</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.253632</td>\n      <td>0.177207</td>\n      <td>0.238408</td>\n      <td>0.138112</td>\n      <td>0.308658</td>\n      <td>0.080762</td>\n      <td>0.049414</td>\n      <td>0.102087</td>\n      <td>0.258081</td>\n      <td>0.150297</td>\n      <td>...</td>\n      <td>0.186766</td>\n      <td>0.128731</td>\n      <td>0.167837</td>\n      <td>0.085504</td>\n      <td>0.222083</td>\n      <td>0.044091</td>\n      <td>0.042060</td>\n      <td>0.164708</td>\n      <td>0.173954</td>\n      <td>0.048506</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.372900</td>\n      <td>0.244505</td>\n      <td>0.353120</td>\n      <td>0.224899</td>\n      <td>0.330505</td>\n      <td>0.157536</td>\n      <td>0.078397</td>\n      <td>0.142992</td>\n      <td>0.259091</td>\n      <td>0.149198</td>\n      <td>...</td>\n      <td>0.298115</td>\n      <td>0.227079</td>\n      <td>0.258429</td>\n      <td>0.145571</td>\n      <td>0.334346</td>\n      <td>0.140247</td>\n      <td>0.104274</td>\n      <td>0.273918</td>\n      <td>0.227899</td>\n      <td>0.139844</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.310426</td>\n      <td>0.157254</td>\n      <td>0.301776</td>\n      <td>0.179343</td>\n      <td>0.407692</td>\n      <td>0.189896</td>\n      <td>0.156139</td>\n      <td>0.237624</td>\n      <td>0.416667</td>\n      <td>0.163041</td>\n      <td>...</td>\n      <td>0.255425</td>\n      <td>0.192964</td>\n      <td>0.245480</td>\n      <td>0.129276</td>\n      <td>0.480948</td>\n      <td>0.164736</td>\n      <td>0.204274</td>\n      <td>0.442612</td>\n      <td>0.335314</td>\n      <td>0.186101</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.610961</td>\n      <td>0.356781</td>\n      <td>0.599198</td>\n      <td>0.454083</td>\n      <td>0.461045</td>\n      <td>0.342372</td>\n      <td>0.330600</td>\n      <td>0.468738</td>\n      <td>0.374747</td>\n      <td>0.255768</td>\n      <td>...</td>\n      <td>0.562078</td>\n      <td>0.352079</td>\n      <td>0.548284</td>\n      <td>0.359025</td>\n      <td>0.465760</td>\n      <td>0.333414</td>\n      <td>0.357692</td>\n      <td>0.554296</td>\n      <td>0.233603</td>\n      <td>0.387086</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.642198</td>\n      <td>0.377071</td>\n      <td>0.649644</td>\n      <td>0.493955</td>\n      <td>0.469170</td>\n      <td>0.473959</td>\n      <td>0.488519</td>\n      <td>0.657058</td>\n      <td>0.538889</td>\n      <td>0.269611</td>\n      <td>...</td>\n      <td>0.582355</td>\n      <td>0.358742</td>\n      <td>0.546790</td>\n      <td>0.399086</td>\n      <td>0.367364</td>\n      <td>0.314306</td>\n      <td>0.378889</td>\n      <td>0.738144</td>\n      <td>0.359078</td>\n      <td>0.219295</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.237068</td>\n      <td>0.513358</td>\n      <td>0.233709</td>\n      <td>0.126320</td>\n      <td>0.454726</td>\n      <td>0.223299</td>\n      <td>0.127484</td>\n      <td>0.212425</td>\n      <td>0.383838</td>\n      <td>0.401230</td>\n      <td>...</td>\n      <td>0.179651</td>\n      <td>0.488806</td>\n      <td>0.169680</td>\n      <td>0.080785</td>\n      <td>0.395760</td>\n      <td>0.170117</td>\n      <td>0.137521</td>\n      <td>0.413058</td>\n      <td>0.245485</td>\n      <td>0.292323</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows Ã— 30 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_columns = x.columns\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_train_scaled = min_max_scaler.fit_transform(x_train)\n",
    "x_train_scaled = pd.DataFrame(x_train_scaled, columns=x_columns)\n",
    "x_train_scaled.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:27:49.554270400Z",
     "start_time": "2023-08-01T00:27:49.473915100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n0     0.358390      0.185280        0.372907   0.233555         0.469146   \n1     0.280557      0.426145        0.281400   0.175130         0.640259   \n2     0.269292      0.290273        0.260167   0.165080         0.434115   \n3     0.543755      0.422028        0.525269   0.418638         0.237133   \n4     0.380921      1.000000        0.361618   0.264041         0.201024   \n5     0.433663      0.574370        0.432566   0.307463         0.438157   \n6     0.588817      0.286155        0.582835   0.474418         0.251415   \n7     0.531978      0.589810        0.516298   0.410464         0.073161   \n8     0.142813      0.487905        0.137410   0.080448         0.521692   \n9     0.350197      0.185280        0.340311   0.227832         0.560765   \n\n   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n0          0.535712        0.454688             0.335463       0.585227   \n1          0.315919        0.384447             0.390841       0.619318   \n2          0.157269        0.193007             0.179446       0.296266   \n3          0.176342        0.256162             0.309585       0.207792   \n4          0.036002        0.146943             0.145847       0.395292   \n5          0.335174        0.327062             0.298882       0.645292   \n6          0.299208        0.374098             0.514750       0.305195   \n7          0.182664        0.345876             0.307668       0.328734   \n8          0.085628        0.151489             0.163472       0.301948   \n9          0.204461        0.216212             0.345847       0.231331   \n\n   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n0                0.507582  ...      0.318386       0.116297         0.358427   \n1                0.375105  ...      0.286065       0.496440         0.290482   \n2                0.310447  ...      0.207103       0.179193         0.206362   \n3                0.090354  ...      0.516815       0.433544         0.509350   \n4                0.062763  ...      0.351117       0.850870         0.334376   \n5                0.188500  ...      0.441535       0.643987         0.452228   \n6                0.037911  ...      0.546273       0.095332         0.553845   \n7                0.072452  ...      0.453400       0.367880         0.448620   \n8                0.304128  ...      0.114639       0.556171         0.115387   \n9                0.236942  ...      0.291384       0.060522         0.292285   \n\n   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n0    0.195696          0.353512           0.310115         0.257109   \n1    0.179054          0.743379           0.362862         0.399840   \n2    0.120906          0.494160           0.154457         0.178994   \n3    0.396471          0.289357           0.191906         0.282588   \n4    0.236533          0.218621           0.047035         0.123562   \n5    0.317939          0.421780           0.252501         0.238978   \n6    0.424876          0.198881           0.149291         0.180831   \n7    0.335650          0.000000           0.144026         0.202476   \n8    0.059885          0.520480           0.050949         0.094329   \n9    0.175879          0.382300           0.095849         0.109665   \n\n   concave points_worst  symmetry_worst  fractal_dimension_worst  \n0              0.412202        0.248768                 0.242949  \n1              0.776786        0.460280                 0.412305  \n2              0.392857        0.357776                 0.267611  \n3              0.584449        0.323477                 0.094057  \n4              0.244606        0.328800                 0.043356  \n5              0.488095        0.377489                 0.138725  \n6              0.661086        0.173073                 0.048996  \n7              0.341555        0.158486                 0.069133  \n8              0.250595        0.259807                 0.147186  \n9              0.397693        0.205204                 0.151253  \n\n[10 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>fractal_dimension_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.358390</td>\n      <td>0.185280</td>\n      <td>0.372907</td>\n      <td>0.233555</td>\n      <td>0.469146</td>\n      <td>0.535712</td>\n      <td>0.454688</td>\n      <td>0.335463</td>\n      <td>0.585227</td>\n      <td>0.507582</td>\n      <td>...</td>\n      <td>0.318386</td>\n      <td>0.116297</td>\n      <td>0.358427</td>\n      <td>0.195696</td>\n      <td>0.353512</td>\n      <td>0.310115</td>\n      <td>0.257109</td>\n      <td>0.412202</td>\n      <td>0.248768</td>\n      <td>0.242949</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.280557</td>\n      <td>0.426145</td>\n      <td>0.281400</td>\n      <td>0.175130</td>\n      <td>0.640259</td>\n      <td>0.315919</td>\n      <td>0.384447</td>\n      <td>0.390841</td>\n      <td>0.619318</td>\n      <td>0.375105</td>\n      <td>...</td>\n      <td>0.286065</td>\n      <td>0.496440</td>\n      <td>0.290482</td>\n      <td>0.179054</td>\n      <td>0.743379</td>\n      <td>0.362862</td>\n      <td>0.399840</td>\n      <td>0.776786</td>\n      <td>0.460280</td>\n      <td>0.412305</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.269292</td>\n      <td>0.290273</td>\n      <td>0.260167</td>\n      <td>0.165080</td>\n      <td>0.434115</td>\n      <td>0.157269</td>\n      <td>0.193007</td>\n      <td>0.179446</td>\n      <td>0.296266</td>\n      <td>0.310447</td>\n      <td>...</td>\n      <td>0.207103</td>\n      <td>0.179193</td>\n      <td>0.206362</td>\n      <td>0.120906</td>\n      <td>0.494160</td>\n      <td>0.154457</td>\n      <td>0.178994</td>\n      <td>0.392857</td>\n      <td>0.357776</td>\n      <td>0.267611</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.543755</td>\n      <td>0.422028</td>\n      <td>0.525269</td>\n      <td>0.418638</td>\n      <td>0.237133</td>\n      <td>0.176342</td>\n      <td>0.256162</td>\n      <td>0.309585</td>\n      <td>0.207792</td>\n      <td>0.090354</td>\n      <td>...</td>\n      <td>0.516815</td>\n      <td>0.433544</td>\n      <td>0.509350</td>\n      <td>0.396471</td>\n      <td>0.289357</td>\n      <td>0.191906</td>\n      <td>0.282588</td>\n      <td>0.584449</td>\n      <td>0.323477</td>\n      <td>0.094057</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.380921</td>\n      <td>1.000000</td>\n      <td>0.361618</td>\n      <td>0.264041</td>\n      <td>0.201024</td>\n      <td>0.036002</td>\n      <td>0.146943</td>\n      <td>0.145847</td>\n      <td>0.395292</td>\n      <td>0.062763</td>\n      <td>...</td>\n      <td>0.351117</td>\n      <td>0.850870</td>\n      <td>0.334376</td>\n      <td>0.236533</td>\n      <td>0.218621</td>\n      <td>0.047035</td>\n      <td>0.123562</td>\n      <td>0.244606</td>\n      <td>0.328800</td>\n      <td>0.043356</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.433663</td>\n      <td>0.574370</td>\n      <td>0.432566</td>\n      <td>0.307463</td>\n      <td>0.438157</td>\n      <td>0.335174</td>\n      <td>0.327062</td>\n      <td>0.298882</td>\n      <td>0.645292</td>\n      <td>0.188500</td>\n      <td>...</td>\n      <td>0.441535</td>\n      <td>0.643987</td>\n      <td>0.452228</td>\n      <td>0.317939</td>\n      <td>0.421780</td>\n      <td>0.252501</td>\n      <td>0.238978</td>\n      <td>0.488095</td>\n      <td>0.377489</td>\n      <td>0.138725</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.588817</td>\n      <td>0.286155</td>\n      <td>0.582835</td>\n      <td>0.474418</td>\n      <td>0.251415</td>\n      <td>0.299208</td>\n      <td>0.374098</td>\n      <td>0.514750</td>\n      <td>0.305195</td>\n      <td>0.037911</td>\n      <td>...</td>\n      <td>0.546273</td>\n      <td>0.095332</td>\n      <td>0.553845</td>\n      <td>0.424876</td>\n      <td>0.198881</td>\n      <td>0.149291</td>\n      <td>0.180831</td>\n      <td>0.661086</td>\n      <td>0.173073</td>\n      <td>0.048996</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.531978</td>\n      <td>0.589810</td>\n      <td>0.516298</td>\n      <td>0.410464</td>\n      <td>0.073161</td>\n      <td>0.182664</td>\n      <td>0.345876</td>\n      <td>0.307668</td>\n      <td>0.328734</td>\n      <td>0.072452</td>\n      <td>...</td>\n      <td>0.453400</td>\n      <td>0.367880</td>\n      <td>0.448620</td>\n      <td>0.335650</td>\n      <td>0.000000</td>\n      <td>0.144026</td>\n      <td>0.202476</td>\n      <td>0.341555</td>\n      <td>0.158486</td>\n      <td>0.069133</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.142813</td>\n      <td>0.487905</td>\n      <td>0.137410</td>\n      <td>0.080448</td>\n      <td>0.521692</td>\n      <td>0.085628</td>\n      <td>0.151489</td>\n      <td>0.163472</td>\n      <td>0.301948</td>\n      <td>0.304128</td>\n      <td>...</td>\n      <td>0.114639</td>\n      <td>0.556171</td>\n      <td>0.115387</td>\n      <td>0.059885</td>\n      <td>0.520480</td>\n      <td>0.050949</td>\n      <td>0.094329</td>\n      <td>0.250595</td>\n      <td>0.259807</td>\n      <td>0.147186</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.350197</td>\n      <td>0.185280</td>\n      <td>0.340311</td>\n      <td>0.227832</td>\n      <td>0.560765</td>\n      <td>0.204461</td>\n      <td>0.216212</td>\n      <td>0.345847</td>\n      <td>0.231331</td>\n      <td>0.236942</td>\n      <td>...</td>\n      <td>0.291384</td>\n      <td>0.060522</td>\n      <td>0.292285</td>\n      <td>0.175879</td>\n      <td>0.382300</td>\n      <td>0.095849</td>\n      <td>0.109665</td>\n      <td>0.397693</td>\n      <td>0.205204</td>\n      <td>0.151253</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows Ã— 30 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_scaled = min_max_scaler.fit_transform(x_test)\n",
    "x_test_scaled = pd.DataFrame(x_test_scaled, columns=x_columns)\n",
    "x_test_scaled.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:27:49.554270400Z",
     "start_time": "2023-08-01T00:27:49.504676200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:27:49.554270400Z",
     "start_time": "2023-08-01T00:27:49.528447300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:27:49.774360300Z",
     "start_time": "2023-08-01T00:27:49.534003500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators: 5 / Depth: 5 --- Accuracy: 0.886 / Precision: 0.796 / Recall: 0.929\n",
      "Estimators: 5 / Depth: 10 --- Accuracy: 0.877 / Precision: 0.780 / Recall: 0.929\n",
      "Estimators: 5 / Depth: 20 --- Accuracy: 0.877 / Precision: 0.780 / Recall: 0.929\n",
      "Estimators: 5 / Depth: 30 --- Accuracy: 0.877 / Precision: 0.780 / Recall: 0.929\n",
      "Estimators: 5 / Depth: None --- Accuracy: 0.877 / Precision: 0.780 / Recall: 0.929\n",
      "Estimators: 10 / Depth: 5 --- Accuracy: 0.921 / Precision: 0.867 / Recall: 0.929\n",
      "Estimators: 10 / Depth: 10 --- Accuracy: 0.895 / Precision: 0.826 / Recall: 0.905\n",
      "Estimators: 10 / Depth: 20 --- Accuracy: 0.895 / Precision: 0.826 / Recall: 0.905\n",
      "Estimators: 10 / Depth: 30 --- Accuracy: 0.895 / Precision: 0.826 / Recall: 0.905\n",
      "Estimators: 10 / Depth: None --- Accuracy: 0.895 / Precision: 0.826 / Recall: 0.905\n",
      "Estimators: 20 / Depth: 5 --- Accuracy: 0.912 / Precision: 0.848 / Recall: 0.929\n",
      "Estimators: 20 / Depth: 10 --- Accuracy: 0.904 / Precision: 0.860 / Recall: 0.881\n",
      "Estimators: 20 / Depth: 20 --- Accuracy: 0.904 / Precision: 0.860 / Recall: 0.881\n",
      "Estimators: 20 / Depth: 30 --- Accuracy: 0.904 / Precision: 0.860 / Recall: 0.881\n",
      "Estimators: 20 / Depth: None --- Accuracy: 0.904 / Precision: 0.860 / Recall: 0.881\n",
      "Estimators: 50 / Depth: 5 --- Accuracy: 0.912 / Precision: 0.881 / Recall: 0.881\n",
      "Estimators: 50 / Depth: 10 --- Accuracy: 0.930 / Precision: 0.925 / Recall: 0.881\n",
      "Estimators: 50 / Depth: 20 --- Accuracy: 0.930 / Precision: 0.925 / Recall: 0.881\n",
      "Estimators: 50 / Depth: 30 --- Accuracy: 0.930 / Precision: 0.925 / Recall: 0.881\n",
      "Estimators: 50 / Depth: None --- Accuracy: 0.930 / Precision: 0.925 / Recall: 0.881\n",
      "Estimators: 100 / Depth: 5 --- Accuracy: 0.930 / Precision: 0.905 / Recall: 0.905\n",
      "Estimators: 100 / Depth: 10 --- Accuracy: 0.930 / Precision: 0.905 / Recall: 0.905\n",
      "Estimators: 100 / Depth: 20 --- Accuracy: 0.930 / Precision: 0.905 / Recall: 0.905\n",
      "Estimators: 100 / Depth: 30 --- Accuracy: 0.930 / Precision: 0.905 / Recall: 0.905\n",
      "Estimators: 100 / Depth: None --- Accuracy: 0.930 / Precision: 0.905 / Recall: 0.905\n"
     ]
    }
   ],
   "source": [
    "num_est = [5, 10, 20, 50, 100]\n",
    "max_depths = [5, 10, 20, 30, None]\n",
    "\n",
    "for est in num_est:\n",
    "    for depth in max_depths:\n",
    "        rf = RandomForestClassifier(n_estimators=est, max_depth=depth, random_state=1)\n",
    "        rf.fit(x_train_scaled, y_train)\n",
    "        y_pred = rf.predict(x_test_scaled)\n",
    "\n",
    "        accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "        precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "        recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "        print(f'Estimators: {est} / Depth: {depth} --- Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:27:52.063971300Z",
     "start_time": "2023-08-01T00:27:49.668175500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:27:52.063971300Z",
     "start_time": "2023-08-01T00:27:52.046153600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty: None / C: 0.0001 --- Accuracy: 0.886 / Precision: 0.774 / Recall: 0.976\n",
      "Penalty: None / C: 0.001 --- Accuracy: 0.886 / Precision: 0.774 / Recall: 0.976\n",
      "Penalty: None / C: 0.01 --- Accuracy: 0.886 / Precision: 0.774 / Recall: 0.976\n",
      "Penalty: None / C: 0.1 --- Accuracy: 0.886 / Precision: 0.774 / Recall: 0.976\n",
      "Penalty: None / C: 1 --- Accuracy: 0.886 / Precision: 0.774 / Recall: 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty: None / C: 10 --- Accuracy: 0.886 / Precision: 0.774 / Recall: 0.976\n",
      "Penalty: l2 / C: 0.0001 --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Penalty: l2 / C: 0.001 --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Penalty: l2 / C: 0.01 --- Accuracy: 0.798 / Precision: 1.000 / Recall: 0.452\n",
      "Penalty: l2 / C: 0.1 --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Penalty: l2 / C: 1 --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "Penalty: l2 / C: 10 --- Accuracy: 0.965 / Precision: 0.952 / Recall: 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "penalties = [None, 'l2']\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "for penalty in penalties:\n",
    "    for c_value in C:\n",
    "        lr = LogisticRegression(penalty=penalty, C=c_value)\n",
    "        lr.fit(x_train_scaled, y_train)\n",
    "        y_pred = lr.predict(x_test_scaled)\n",
    "\n",
    "        accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "        precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "        recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "        print(f'Penalty: {penalty} / C: {c_value} --- Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:27:52.355688500Z",
     "start_time": "2023-08-01T00:27:52.046655Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:27:52.358681Z",
     "start_time": "2023-08-01T00:27:52.355688500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.1 / Kernel: linear --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 0.1 / Kernel: poly / Degree: 1 --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 0.1 / Kernel: poly / Degree: 2 --- Accuracy: 0.965 / Precision: 0.975 / Recall: 0.929\n",
      "C: 0.1 / Kernel: poly / Degree: 3 --- Accuracy: 0.965 / Precision: 0.975 / Recall: 0.929\n",
      "C: 0.1 / Kernel: poly / Degree: 4 --- Accuracy: 0.930 / Precision: 0.905 / Recall: 0.905\n",
      "C: 0.1 / Kernel: poly / Degree: 5 --- Accuracy: 0.904 / Precision: 0.830 / Recall: 0.929\n",
      "C: 0.1 / Kernel: rbf --- Accuracy: 0.956 / Precision: 0.951 / Recall: 0.929\n",
      "C: 0.1 / Kernel: sigmoid --- Accuracy: 0.535 / Precision: 0.000 / Recall: 0.000\n",
      "C: 1 / Kernel: linear --- Accuracy: 0.965 / Precision: 0.975 / Recall: 0.929\n",
      "C: 1 / Kernel: poly / Degree: 1 --- Accuracy: 0.965 / Precision: 0.975 / Recall: 0.929\n",
      "C: 1 / Kernel: poly / Degree: 2 --- Accuracy: 0.965 / Precision: 0.952 / Recall: 0.952\n",
      "C: 1 / Kernel: poly / Degree: 3 --- Accuracy: 0.921 / Precision: 0.837 / Recall: 0.976\n",
      "C: 1 / Kernel: poly / Degree: 4 --- Accuracy: 0.904 / Precision: 0.830 / Recall: 0.929\n",
      "C: 1 / Kernel: poly / Degree: 5 --- Accuracy: 0.895 / Precision: 0.826 / Recall: 0.905\n",
      "C: 1 / Kernel: rbf --- Accuracy: 0.974 / Precision: 0.976 / Recall: 0.952\n",
      "C: 1 / Kernel: sigmoid --- Accuracy: 0.351 / Precision: 0.029 / Recall: 0.024\n",
      "C: 10 / Kernel: linear --- Accuracy: 0.982 / Precision: 0.955 / Recall: 1.000\n",
      "C: 10 / Kernel: poly / Degree: 1 --- Accuracy: 0.982 / Precision: 0.955 / Recall: 1.000\n",
      "C: 10 / Kernel: poly / Degree: 2 --- Accuracy: 0.930 / Precision: 0.854 / Recall: 0.976\n",
      "C: 10 / Kernel: poly / Degree: 3 --- Accuracy: 0.895 / Precision: 0.800 / Recall: 0.952\n",
      "C: 10 / Kernel: poly / Degree: 4 --- Accuracy: 0.886 / Precision: 0.809 / Recall: 0.905\n",
      "C: 10 / Kernel: poly / Degree: 5 --- Accuracy: 0.895 / Precision: 0.857 / Recall: 0.857\n",
      "C: 10 / Kernel: rbf --- Accuracy: 0.930 / Precision: 0.854 / Recall: 0.976\n",
      "C: 10 / Kernel: sigmoid --- Accuracy: 0.342 / Precision: 0.029 / Recall: 0.024\n"
     ]
    }
   ],
   "source": [
    "C = [0.1, 1, 10]\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "degrees = [1, 2, 3, 4, 5]\n",
    "\n",
    "for c_value in C:\n",
    "    for kernel in kernels:\n",
    "        if kernel == 'poly':\n",
    "            for degree in degrees:\n",
    "                svc = SVC(C=c_value, kernel=kernel, degree=degree)\n",
    "                svc.fit(x_train_scaled, y_train)\n",
    "                y_pred = svc.predict(x_test_scaled)\n",
    "\n",
    "                accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "                precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "                recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "                print(f'C: {c_value} / Kernel: {kernel} / Degree: {degree} --- Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')\n",
    "        else:\n",
    "            svc = SVC(C=c_value, kernel=kernel)\n",
    "            svc.fit(x_train_scaled, y_train)\n",
    "            y_pred = svc.predict(x_test_scaled)\n",
    "\n",
    "            accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "            precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "            recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "            print(f'C: {c_value} / Kernel: {kernel} --- Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:27:52.606910Z",
     "start_time": "2023-08-01T00:27:52.358681Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:27:52.607168500Z",
     "start_time": "2023-08-01T00:27:52.585907900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors: 2 / Weight: uniform --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Neighbors: 2 / Weight: distance --- Accuracy: 0.939 / Precision: 0.927 / Recall: 0.905\n",
      "Neighbors: 3 / Weight: uniform --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 3 / Weight: distance --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 4 / Weight: uniform --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Neighbors: 4 / Weight: distance --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 5 / Weight: uniform --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Neighbors: 5 / Weight: distance --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Neighbors: 6 / Weight: uniform --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Neighbors: 6 / Weight: distance --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Neighbors: 7 / Weight: uniform --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "Neighbors: 7 / Weight: distance --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "Neighbors: 8 / Weight: uniform --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Neighbors: 8 / Weight: distance --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "Neighbors: 9 / Weight: uniform --- Accuracy: 0.956 / Precision: 0.974 / Recall: 0.905\n",
      "Neighbors: 9 / Weight: distance --- Accuracy: 0.956 / Precision: 0.974 / Recall: 0.905\n",
      "Neighbors: 10 / Weight: uniform --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Neighbors: 10 / Weight: distance --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "Neighbors: 11 / Weight: uniform --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Neighbors: 11 / Weight: distance --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Neighbors: 12 / Weight: uniform --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Neighbors: 12 / Weight: distance --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "Neighbors: 13 / Weight: uniform --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Neighbors: 13 / Weight: distance --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Neighbors: 14 / Weight: uniform --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Neighbors: 14 / Weight: distance --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n"
     ]
    }
   ],
   "source": [
    "max_num_neighbors = 14\n",
    "weights = ['uniform', 'distance']\n",
    "\n",
    "for num_neighbor in range(2, max_num_neighbors+1):\n",
    "    for weight in weights:\n",
    "        knn = KNeighborsClassifier(n_neighbors=num_neighbor, weights=weight)\n",
    "        knn.fit(x_train_scaled.values, y_train)\n",
    "        y_pred = knn.predict(x_test_scaled.values)\n",
    "\n",
    "        accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "        precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "        recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "        print(f'Neighbors: {num_neighbor} / Weight: {weight} --- Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:27:53.147870Z",
     "start_time": "2023-08-01T00:27:52.594439900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:27:53.147870Z",
     "start_time": "2023-08-01T00:27:53.140237600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: identity / Solver: lbfgs --- Accuracy: 0.904 / Precision: 0.792 / Recall: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: identity / Solver: sgd --- Accuracy: 0.939 / Precision: 0.949 / Recall: 0.881\n",
      "Hidden Layer Size: 10 / Activation: identity / Solver: adam --- Accuracy: 0.939 / Precision: 0.857 / Recall: 1.000\n",
      "Hidden Layer Size: 10 / Activation: logistic / Solver: lbfgs --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: logistic / Solver: sgd --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: logistic / Solver: adam --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Hidden Layer Size: 10 / Activation: tanh / Solver: lbfgs --- Accuracy: 0.904 / Precision: 0.792 / Recall: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: tanh / Solver: sgd --- Accuracy: 0.921 / Precision: 0.946 / Recall: 0.833\n",
      "Hidden Layer Size: 10 / Activation: tanh / Solver: adam --- Accuracy: 0.930 / Precision: 0.840 / Recall: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: relu / Solver: lbfgs --- Accuracy: 0.974 / Precision: 0.976 / Recall: 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: relu / Solver: sgd --- Accuracy: 0.947 / Precision: 0.929 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: relu / Solver: adam --- Accuracy: 0.974 / Precision: 0.976 / Recall: 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 20 / Activation: identity / Solver: lbfgs --- Accuracy: 0.895 / Precision: 0.778 / Recall: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 20 / Activation: identity / Solver: sgd --- Accuracy: 0.930 / Precision: 0.905 / Recall: 0.905\n",
      "Hidden Layer Size: 20 / Activation: identity / Solver: adam --- Accuracy: 0.860 / Precision: 0.724 / Recall: 1.000\n",
      "Hidden Layer Size: 20 / Activation: logistic / Solver: lbfgs --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 20 / Activation: logistic / Solver: sgd --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 20 / Activation: logistic / Solver: adam --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Hidden Layer Size: 20 / Activation: tanh / Solver: lbfgs --- Accuracy: 0.904 / Precision: 0.792 / Recall: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 20 / Activation: tanh / Solver: sgd --- Accuracy: 0.904 / Precision: 0.860 / Recall: 0.881\n",
      "Hidden Layer Size: 20 / Activation: tanh / Solver: adam --- Accuracy: 0.877 / Precision: 0.750 / Recall: 1.000\n",
      "Hidden Layer Size: 20 / Activation: relu / Solver: lbfgs --- Accuracy: 0.939 / Precision: 0.872 / Recall: 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 20 / Activation: relu / Solver: sgd --- Accuracy: 0.912 / Precision: 1.000 / Recall: 0.762\n",
      "Hidden Layer Size: 20 / Activation: relu / Solver: adam --- Accuracy: 0.912 / Precision: 0.833 / Recall: 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 50 / Activation: identity / Solver: lbfgs --- Accuracy: 0.904 / Precision: 0.792 / Recall: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 50 / Activation: identity / Solver: sgd --- Accuracy: 0.947 / Precision: 0.950 / Recall: 0.905\n",
      "Hidden Layer Size: 50 / Activation: identity / Solver: adam --- Accuracy: 0.965 / Precision: 0.952 / Recall: 0.952\n",
      "Hidden Layer Size: 50 / Activation: logistic / Solver: lbfgs --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 50 / Activation: logistic / Solver: sgd --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Hidden Layer Size: 50 / Activation: logistic / Solver: adam --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Hidden Layer Size: 50 / Activation: tanh / Solver: lbfgs --- Accuracy: 0.939 / Precision: 0.857 / Recall: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 50 / Activation: tanh / Solver: sgd --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "Hidden Layer Size: 50 / Activation: tanh / Solver: adam --- Accuracy: 0.904 / Precision: 0.792 / Recall: 1.000\n",
      "Hidden Layer Size: 50 / Activation: relu / Solver: lbfgs --- Accuracy: 0.956 / Precision: 0.911 / Recall: 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 50 / Activation: relu / Solver: sgd --- Accuracy: 0.868 / Precision: 0.776 / Recall: 0.905\n",
      "Hidden Layer Size: 50 / Activation: relu / Solver: adam --- Accuracy: 0.974 / Precision: 0.953 / Recall: 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100 / Activation: identity / Solver: lbfgs --- Accuracy: 0.904 / Precision: 0.792 / Recall: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100 / Activation: identity / Solver: sgd --- Accuracy: 0.956 / Precision: 0.974 / Recall: 0.905\n",
      "Hidden Layer Size: 100 / Activation: identity / Solver: adam --- Accuracy: 0.947 / Precision: 0.909 / Recall: 0.952\n",
      "Hidden Layer Size: 100 / Activation: logistic / Solver: lbfgs --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100 / Activation: logistic / Solver: sgd --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Hidden Layer Size: 100 / Activation: logistic / Solver: adam --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100 / Activation: tanh / Solver: lbfgs --- Accuracy: 0.939 / Precision: 0.907 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100 / Activation: tanh / Solver: sgd --- Accuracy: 0.939 / Precision: 0.949 / Recall: 0.881\n",
      "Hidden Layer Size: 100 / Activation: tanh / Solver: adam --- Accuracy: 0.956 / Precision: 0.930 / Recall: 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100 / Activation: relu / Solver: lbfgs --- Accuracy: 0.965 / Precision: 0.952 / Recall: 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100 / Activation: relu / Solver: sgd --- Accuracy: 0.868 / Precision: 0.909 / Recall: 0.714\n",
      "Hidden Layer Size: 100 / Activation: relu / Solver: adam --- Accuracy: 0.939 / Precision: 0.889 / Recall: 0.952\n"
     ]
    }
   ],
   "source": [
    "num_layers = [10, 20, 50, 100]\n",
    "activation_functions = ['identity', 'logistic', 'tanh', 'relu']\n",
    "solvers = ['lbfgs', 'sgd', 'adam']\n",
    "for layers in num_layers:\n",
    "    for activation in activation_functions:\n",
    "        for solver in solvers:\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=num_layers, activation=activation, solver=solver)\n",
    "            mlp.fit(x_train_scaled, y_train)\n",
    "            y_pred = mlp.predict(x_test_scaled)\n",
    "\n",
    "            accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "            precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "            recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "            print(f'Hidden Layer Size: {layers} / Activation: {activation} / Solver: {solver} --- Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:28:31.393757500Z",
     "start_time": "2023-08-01T00:27:53.147870Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.833 / Precision: 0.709 / Recall: 0.929\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train_scaled, y_train)\n",
    "y_pred = nb.predict(x_test_scaled)\n",
    "\n",
    "accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "print(f'Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:28:31.394757400Z",
     "start_time": "2023-08-01T00:28:31.379315600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.640 / Precision: 0.506 / Recall: 1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(x_train_scaled, y_train)\n",
    "y_pred = qda.predict(x_test_scaled)\n",
    "\n",
    "accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "print(f'Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:28:31.443987Z",
     "start_time": "2023-08-01T00:28:31.394351400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.965 / Precision: 0.975 / Recall: 0.929\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "gp = GaussianProcessClassifier()\n",
    "gp.fit(x_train_scaled, y_train)\n",
    "y_pred = gp.predict(x_test_scaled)\n",
    "\n",
    "accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "print(f'Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:28:31.595830900Z",
     "start_time": "2023-08-01T00:28:31.414149800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:28:31.599200100Z",
     "start_time": "2023-08-01T00:28:31.595830900Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
