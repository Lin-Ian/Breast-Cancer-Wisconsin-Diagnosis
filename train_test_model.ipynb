{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:52:45.319625900Z",
     "start_time": "2023-08-01T14:52:45.240514100Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0         M        17.99         10.38          122.80     1001.0   \n1         M        20.57         17.77          132.90     1326.0   \n2         M        19.69         21.25          130.00     1203.0   \n3         M        11.42         20.38           77.58      386.1   \n4         M        20.29         14.34          135.10     1297.0   \n\n   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0          0.11840           0.27760          0.3001              0.14710   \n1          0.08474           0.07864          0.0869              0.07017   \n2          0.10960           0.15990          0.1974              0.12790   \n3          0.14250           0.28390          0.2414              0.10520   \n4          0.10030           0.13280          0.1980              0.10430   \n\n   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n0         0.2419  ...         25.38          17.33           184.60   \n1         0.1812  ...         24.99          23.41           158.80   \n2         0.2069  ...         23.57          25.53           152.50   \n3         0.2597  ...         14.91          26.50            98.87   \n4         0.1809  ...         22.54          16.67           152.20   \n\n   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n0      2019.0            0.1622             0.6656           0.7119   \n1      1956.0            0.1238             0.1866           0.2416   \n2      1709.0            0.1444             0.4245           0.4504   \n3       567.7            0.2098             0.8663           0.6869   \n4      1575.0            0.1374             0.2050           0.4000   \n\n   concave points_worst  symmetry_worst  fractal_dimension_worst  \n0                0.2654          0.4601                  0.11890  \n1                0.1860          0.2750                  0.08902  \n2                0.2430          0.3613                  0.08758  \n3                0.2575          0.6638                  0.17300  \n4                0.1625          0.2364                  0.07678  \n\n[5 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>...</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/cleaned_data.csv')\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:53:28.669607100Z",
     "start_time": "2023-08-01T14:53:28.632666700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "x = data.drop(['diagnosis'], axis=1)\n",
    "y = data['diagnosis']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:53:30.192831700Z",
     "start_time": "2023-08-01T14:53:30.188750600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:53:31.028875500Z",
     "start_time": "2023-08-01T14:53:30.898060900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "((455, 30), (114, 30), (455,), (114,))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:53:31.360019300Z",
     "start_time": "2023-08-01T14:53:31.337932100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:53:32.609696800Z",
     "start_time": "2023-08-01T14:53:32.594459800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n0     0.521037      0.370308        0.511437   0.359788         0.460143   \n1     0.629893      0.156578        0.630986   0.489290         0.430351   \n2     0.095556      0.158607        0.086863   0.043606         0.157263   \n3     0.247480      0.148123        0.241794   0.135101         0.256838   \n4     0.253632      0.177207        0.238408   0.138112         0.308658   \n5     0.372900      0.244505        0.353120   0.224899         0.330505   \n6     0.310426      0.157254        0.301776   0.179343         0.407692   \n7     0.610961      0.356781        0.599198   0.454083         0.461045   \n8     0.642198      0.377071        0.649644   0.493955         0.469170   \n9     0.237068      0.513358        0.233709   0.126320         0.454726   \n\n   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n0          0.340531        0.281396             0.438569       0.470707   \n1          0.347893        0.463918             0.518390       0.378283   \n2          0.036133        0.008625             0.017256       0.367677   \n3          0.180510        0.160239             0.125944       0.295960   \n4          0.080762        0.049414             0.102087       0.258081   \n5          0.157536        0.078397             0.142992       0.259091   \n6          0.189896        0.156139             0.237624       0.416667   \n7          0.342372        0.330600             0.468738       0.374747   \n8          0.473959        0.488519             0.657058       0.538889   \n9          0.223299        0.127484             0.212425       0.383838   \n\n   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n0                0.229620  ...      0.467805       0.356876         0.436725   \n1                0.188750  ...      0.519744       0.123934         0.506948   \n2                0.397495  ...      0.062931       0.214552         0.052244   \n3                0.248297  ...      0.184988       0.193763         0.185467   \n4                0.150297  ...      0.186766       0.128731         0.167837   \n5                0.149198  ...      0.298115       0.227079         0.258429   \n6                0.163041  ...      0.255425       0.192964         0.245480   \n7                0.255768  ...      0.562078       0.352079         0.548284   \n8                0.269611  ...      0.582355       0.358742         0.546790   \n9                0.401230  ...      0.179651       0.488806         0.169680   \n\n   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n0    0.286030          0.508684           0.380196         0.282137   \n1    0.341575          0.437364           0.195155         0.341880   \n2    0.024651          0.181206           0.027487         0.012581   \n3    0.084718          0.207555           0.236995         0.262906   \n4    0.085504          0.222083           0.044091         0.042060   \n5    0.145571          0.334346           0.140247         0.104274   \n6    0.129276          0.480948           0.164736         0.204274   \n7    0.359025          0.465760           0.333414         0.357692   \n8    0.399086          0.367364           0.314306         0.378889   \n9    0.080785          0.395760           0.170117         0.137521   \n\n   concave points_worst  symmetry_worst  fractal_dimension_worst  \n0              0.678351        0.355038                 0.319306  \n1              0.558419        0.189639                 0.230967  \n2              0.047732        0.338641                 0.244459  \n3              0.314089        0.264021                 0.353678  \n4              0.164708        0.173954                 0.048506  \n5              0.273918        0.227899                 0.139844  \n6              0.442612        0.335314                 0.186101  \n7              0.554296        0.233603                 0.387086  \n8              0.738144        0.359078                 0.219295  \n9              0.413058        0.245485                 0.292323  \n\n[10 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>fractal_dimension_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.521037</td>\n      <td>0.370308</td>\n      <td>0.511437</td>\n      <td>0.359788</td>\n      <td>0.460143</td>\n      <td>0.340531</td>\n      <td>0.281396</td>\n      <td>0.438569</td>\n      <td>0.470707</td>\n      <td>0.229620</td>\n      <td>...</td>\n      <td>0.467805</td>\n      <td>0.356876</td>\n      <td>0.436725</td>\n      <td>0.286030</td>\n      <td>0.508684</td>\n      <td>0.380196</td>\n      <td>0.282137</td>\n      <td>0.678351</td>\n      <td>0.355038</td>\n      <td>0.319306</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.629893</td>\n      <td>0.156578</td>\n      <td>0.630986</td>\n      <td>0.489290</td>\n      <td>0.430351</td>\n      <td>0.347893</td>\n      <td>0.463918</td>\n      <td>0.518390</td>\n      <td>0.378283</td>\n      <td>0.188750</td>\n      <td>...</td>\n      <td>0.519744</td>\n      <td>0.123934</td>\n      <td>0.506948</td>\n      <td>0.341575</td>\n      <td>0.437364</td>\n      <td>0.195155</td>\n      <td>0.341880</td>\n      <td>0.558419</td>\n      <td>0.189639</td>\n      <td>0.230967</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.095556</td>\n      <td>0.158607</td>\n      <td>0.086863</td>\n      <td>0.043606</td>\n      <td>0.157263</td>\n      <td>0.036133</td>\n      <td>0.008625</td>\n      <td>0.017256</td>\n      <td>0.367677</td>\n      <td>0.397495</td>\n      <td>...</td>\n      <td>0.062931</td>\n      <td>0.214552</td>\n      <td>0.052244</td>\n      <td>0.024651</td>\n      <td>0.181206</td>\n      <td>0.027487</td>\n      <td>0.012581</td>\n      <td>0.047732</td>\n      <td>0.338641</td>\n      <td>0.244459</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.247480</td>\n      <td>0.148123</td>\n      <td>0.241794</td>\n      <td>0.135101</td>\n      <td>0.256838</td>\n      <td>0.180510</td>\n      <td>0.160239</td>\n      <td>0.125944</td>\n      <td>0.295960</td>\n      <td>0.248297</td>\n      <td>...</td>\n      <td>0.184988</td>\n      <td>0.193763</td>\n      <td>0.185467</td>\n      <td>0.084718</td>\n      <td>0.207555</td>\n      <td>0.236995</td>\n      <td>0.262906</td>\n      <td>0.314089</td>\n      <td>0.264021</td>\n      <td>0.353678</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.253632</td>\n      <td>0.177207</td>\n      <td>0.238408</td>\n      <td>0.138112</td>\n      <td>0.308658</td>\n      <td>0.080762</td>\n      <td>0.049414</td>\n      <td>0.102087</td>\n      <td>0.258081</td>\n      <td>0.150297</td>\n      <td>...</td>\n      <td>0.186766</td>\n      <td>0.128731</td>\n      <td>0.167837</td>\n      <td>0.085504</td>\n      <td>0.222083</td>\n      <td>0.044091</td>\n      <td>0.042060</td>\n      <td>0.164708</td>\n      <td>0.173954</td>\n      <td>0.048506</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.372900</td>\n      <td>0.244505</td>\n      <td>0.353120</td>\n      <td>0.224899</td>\n      <td>0.330505</td>\n      <td>0.157536</td>\n      <td>0.078397</td>\n      <td>0.142992</td>\n      <td>0.259091</td>\n      <td>0.149198</td>\n      <td>...</td>\n      <td>0.298115</td>\n      <td>0.227079</td>\n      <td>0.258429</td>\n      <td>0.145571</td>\n      <td>0.334346</td>\n      <td>0.140247</td>\n      <td>0.104274</td>\n      <td>0.273918</td>\n      <td>0.227899</td>\n      <td>0.139844</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.310426</td>\n      <td>0.157254</td>\n      <td>0.301776</td>\n      <td>0.179343</td>\n      <td>0.407692</td>\n      <td>0.189896</td>\n      <td>0.156139</td>\n      <td>0.237624</td>\n      <td>0.416667</td>\n      <td>0.163041</td>\n      <td>...</td>\n      <td>0.255425</td>\n      <td>0.192964</td>\n      <td>0.245480</td>\n      <td>0.129276</td>\n      <td>0.480948</td>\n      <td>0.164736</td>\n      <td>0.204274</td>\n      <td>0.442612</td>\n      <td>0.335314</td>\n      <td>0.186101</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.610961</td>\n      <td>0.356781</td>\n      <td>0.599198</td>\n      <td>0.454083</td>\n      <td>0.461045</td>\n      <td>0.342372</td>\n      <td>0.330600</td>\n      <td>0.468738</td>\n      <td>0.374747</td>\n      <td>0.255768</td>\n      <td>...</td>\n      <td>0.562078</td>\n      <td>0.352079</td>\n      <td>0.548284</td>\n      <td>0.359025</td>\n      <td>0.465760</td>\n      <td>0.333414</td>\n      <td>0.357692</td>\n      <td>0.554296</td>\n      <td>0.233603</td>\n      <td>0.387086</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.642198</td>\n      <td>0.377071</td>\n      <td>0.649644</td>\n      <td>0.493955</td>\n      <td>0.469170</td>\n      <td>0.473959</td>\n      <td>0.488519</td>\n      <td>0.657058</td>\n      <td>0.538889</td>\n      <td>0.269611</td>\n      <td>...</td>\n      <td>0.582355</td>\n      <td>0.358742</td>\n      <td>0.546790</td>\n      <td>0.399086</td>\n      <td>0.367364</td>\n      <td>0.314306</td>\n      <td>0.378889</td>\n      <td>0.738144</td>\n      <td>0.359078</td>\n      <td>0.219295</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.237068</td>\n      <td>0.513358</td>\n      <td>0.233709</td>\n      <td>0.126320</td>\n      <td>0.454726</td>\n      <td>0.223299</td>\n      <td>0.127484</td>\n      <td>0.212425</td>\n      <td>0.383838</td>\n      <td>0.401230</td>\n      <td>...</td>\n      <td>0.179651</td>\n      <td>0.488806</td>\n      <td>0.169680</td>\n      <td>0.080785</td>\n      <td>0.395760</td>\n      <td>0.170117</td>\n      <td>0.137521</td>\n      <td>0.413058</td>\n      <td>0.245485</td>\n      <td>0.292323</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows Ã— 30 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_columns = x.columns\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_train_scaled = min_max_scaler.fit_transform(x_train)\n",
    "x_train_scaled = pd.DataFrame(x_train_scaled, columns=x_columns)\n",
    "x_train_scaled.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:53:33.083952Z",
     "start_time": "2023-08-01T14:53:33.057705100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n0     0.364854      0.144403        0.376132   0.217434         0.455629   \n1     0.292915      0.302672        0.291549   0.165896         0.570281   \n2     0.282503      0.213392        0.271923   0.157031         0.432157   \n3     0.536182      0.299966        0.516965   0.380700         0.300172   \n4     0.385678      0.679743        0.365697   0.244327         0.275977   \n5     0.434427      0.400068        0.431276   0.282630         0.434865   \n6     0.577831      0.210687        0.570175   0.429905         0.309741   \n7     0.525297      0.410213        0.508673   0.373489         0.190304   \n8     0.165602      0.343253        0.158455   0.082375         0.490837   \n9     0.357281      0.144403        0.346002   0.212386         0.517017   \n\n   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n0          0.503711        0.339738             0.313121       0.518182   \n1          0.318140        0.287254             0.364811       0.539394   \n2          0.184191        0.144213             0.167495       0.338384   \n3          0.200294        0.191401             0.288966       0.283333   \n4          0.081805        0.109794             0.136133       0.400000   \n5          0.334397        0.244377             0.278976       0.555556   \n6          0.304030        0.279522             0.480467       0.343939   \n7          0.205632        0.258435             0.287177       0.358586   \n8          0.123704        0.113191             0.152584       0.341919   \n9          0.224035        0.161551             0.322813       0.297980   \n\n   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n0                0.523401  ...      0.303451       0.168443         0.317197   \n1                0.385190  ...      0.275347       0.424574         0.260919   \n2                0.317732  ...      0.206688       0.210821         0.191245   \n3                0.088113  ...      0.475987       0.382196         0.442203   \n4                0.059328  ...      0.331910       0.663380         0.297276   \n5                0.190508  ...      0.410530       0.523987         0.394890   \n6                0.033399  ...      0.501601       0.154318         0.479058   \n7                0.069435  ...      0.420847       0.337953         0.391902   \n8                0.311140  ...      0.126290       0.464819         0.115892   \n9                0.241046  ...      0.279972       0.130864         0.262413   \n\n   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n0    0.153362          0.396421           0.369214         0.275128   \n1    0.141123          0.709437           0.427527         0.427863   \n2    0.098358          0.509344           0.197132         0.191538   \n3    0.301022          0.344912           0.238532         0.302393   \n4    0.183396          0.288120           0.078376         0.132222   \n5    0.243266          0.451232           0.305520         0.255726   \n6    0.321913          0.272271           0.191421         0.193504   \n7    0.256292          0.112593           0.185601         0.216667   \n8    0.053480          0.530476           0.082703         0.100940   \n9    0.138788          0.419534           0.132340         0.117350   \n\n   concave points_worst  symmetry_worst  fractal_dimension_worst  \n0              0.380756        0.299667                 0.394796  \n1              0.717526        0.554658                 0.671271  \n2              0.362887        0.431084                 0.435057  \n3              0.539863        0.389734                 0.151729  \n4              0.225945        0.396150                 0.068958  \n5              0.450859        0.454848                 0.224649  \n6              0.610653        0.208413                 0.078167  \n7              0.315498        0.190827                 0.111040  \n8              0.231478        0.312975                 0.238462  \n9              0.367354        0.247148                 0.245101  \n\n[10 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>fractal_dimension_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.364854</td>\n      <td>0.144403</td>\n      <td>0.376132</td>\n      <td>0.217434</td>\n      <td>0.455629</td>\n      <td>0.503711</td>\n      <td>0.339738</td>\n      <td>0.313121</td>\n      <td>0.518182</td>\n      <td>0.523401</td>\n      <td>...</td>\n      <td>0.303451</td>\n      <td>0.168443</td>\n      <td>0.317197</td>\n      <td>0.153362</td>\n      <td>0.396421</td>\n      <td>0.369214</td>\n      <td>0.275128</td>\n      <td>0.380756</td>\n      <td>0.299667</td>\n      <td>0.394796</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.292915</td>\n      <td>0.302672</td>\n      <td>0.291549</td>\n      <td>0.165896</td>\n      <td>0.570281</td>\n      <td>0.318140</td>\n      <td>0.287254</td>\n      <td>0.364811</td>\n      <td>0.539394</td>\n      <td>0.385190</td>\n      <td>...</td>\n      <td>0.275347</td>\n      <td>0.424574</td>\n      <td>0.260919</td>\n      <td>0.141123</td>\n      <td>0.709437</td>\n      <td>0.427527</td>\n      <td>0.427863</td>\n      <td>0.717526</td>\n      <td>0.554658</td>\n      <td>0.671271</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.282503</td>\n      <td>0.213392</td>\n      <td>0.271923</td>\n      <td>0.157031</td>\n      <td>0.432157</td>\n      <td>0.184191</td>\n      <td>0.144213</td>\n      <td>0.167495</td>\n      <td>0.338384</td>\n      <td>0.317732</td>\n      <td>...</td>\n      <td>0.206688</td>\n      <td>0.210821</td>\n      <td>0.191245</td>\n      <td>0.098358</td>\n      <td>0.509344</td>\n      <td>0.197132</td>\n      <td>0.191538</td>\n      <td>0.362887</td>\n      <td>0.431084</td>\n      <td>0.435057</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.536182</td>\n      <td>0.299966</td>\n      <td>0.516965</td>\n      <td>0.380700</td>\n      <td>0.300172</td>\n      <td>0.200294</td>\n      <td>0.191401</td>\n      <td>0.288966</td>\n      <td>0.283333</td>\n      <td>0.088113</td>\n      <td>...</td>\n      <td>0.475987</td>\n      <td>0.382196</td>\n      <td>0.442203</td>\n      <td>0.301022</td>\n      <td>0.344912</td>\n      <td>0.238532</td>\n      <td>0.302393</td>\n      <td>0.539863</td>\n      <td>0.389734</td>\n      <td>0.151729</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.385678</td>\n      <td>0.679743</td>\n      <td>0.365697</td>\n      <td>0.244327</td>\n      <td>0.275977</td>\n      <td>0.081805</td>\n      <td>0.109794</td>\n      <td>0.136133</td>\n      <td>0.400000</td>\n      <td>0.059328</td>\n      <td>...</td>\n      <td>0.331910</td>\n      <td>0.663380</td>\n      <td>0.297276</td>\n      <td>0.183396</td>\n      <td>0.288120</td>\n      <td>0.078376</td>\n      <td>0.132222</td>\n      <td>0.225945</td>\n      <td>0.396150</td>\n      <td>0.068958</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.434427</td>\n      <td>0.400068</td>\n      <td>0.431276</td>\n      <td>0.282630</td>\n      <td>0.434865</td>\n      <td>0.334397</td>\n      <td>0.244377</td>\n      <td>0.278976</td>\n      <td>0.555556</td>\n      <td>0.190508</td>\n      <td>...</td>\n      <td>0.410530</td>\n      <td>0.523987</td>\n      <td>0.394890</td>\n      <td>0.243266</td>\n      <td>0.451232</td>\n      <td>0.305520</td>\n      <td>0.255726</td>\n      <td>0.450859</td>\n      <td>0.454848</td>\n      <td>0.224649</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.577831</td>\n      <td>0.210687</td>\n      <td>0.570175</td>\n      <td>0.429905</td>\n      <td>0.309741</td>\n      <td>0.304030</td>\n      <td>0.279522</td>\n      <td>0.480467</td>\n      <td>0.343939</td>\n      <td>0.033399</td>\n      <td>...</td>\n      <td>0.501601</td>\n      <td>0.154318</td>\n      <td>0.479058</td>\n      <td>0.321913</td>\n      <td>0.272271</td>\n      <td>0.191421</td>\n      <td>0.193504</td>\n      <td>0.610653</td>\n      <td>0.208413</td>\n      <td>0.078167</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.525297</td>\n      <td>0.410213</td>\n      <td>0.508673</td>\n      <td>0.373489</td>\n      <td>0.190304</td>\n      <td>0.205632</td>\n      <td>0.258435</td>\n      <td>0.287177</td>\n      <td>0.358586</td>\n      <td>0.069435</td>\n      <td>...</td>\n      <td>0.420847</td>\n      <td>0.337953</td>\n      <td>0.391902</td>\n      <td>0.256292</td>\n      <td>0.112593</td>\n      <td>0.185601</td>\n      <td>0.216667</td>\n      <td>0.315498</td>\n      <td>0.190827</td>\n      <td>0.111040</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.165602</td>\n      <td>0.343253</td>\n      <td>0.158455</td>\n      <td>0.082375</td>\n      <td>0.490837</td>\n      <td>0.123704</td>\n      <td>0.113191</td>\n      <td>0.152584</td>\n      <td>0.341919</td>\n      <td>0.311140</td>\n      <td>...</td>\n      <td>0.126290</td>\n      <td>0.464819</td>\n      <td>0.115892</td>\n      <td>0.053480</td>\n      <td>0.530476</td>\n      <td>0.082703</td>\n      <td>0.100940</td>\n      <td>0.231478</td>\n      <td>0.312975</td>\n      <td>0.238462</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.357281</td>\n      <td>0.144403</td>\n      <td>0.346002</td>\n      <td>0.212386</td>\n      <td>0.517017</td>\n      <td>0.224035</td>\n      <td>0.161551</td>\n      <td>0.322813</td>\n      <td>0.297980</td>\n      <td>0.241046</td>\n      <td>...</td>\n      <td>0.279972</td>\n      <td>0.130864</td>\n      <td>0.262413</td>\n      <td>0.138788</td>\n      <td>0.419534</td>\n      <td>0.132340</td>\n      <td>0.117350</td>\n      <td>0.367354</td>\n      <td>0.247148</td>\n      <td>0.245101</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows Ã— 30 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_scaled = min_max_scaler.transform(x_test)\n",
    "x_test_scaled = pd.DataFrame(x_test_scaled, columns=x_columns)\n",
    "x_test_scaled.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:53:34.432240700Z",
     "start_time": "2023-08-01T14:53:34.413643100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:47:51.035568800Z",
     "start_time": "2023-08-01T14:47:51.035066Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:27.133334400Z",
     "start_time": "2023-08-01T00:55:26.949434400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators: 5 / Depth: 5 --- Accuracy: 0.939 / Precision: 1.000 / Recall: 0.833\n",
      "Estimators: 5 / Depth: 10 --- Accuracy: 0.956 / Precision: 0.974 / Recall: 0.905\n",
      "Estimators: 5 / Depth: 20 --- Accuracy: 0.956 / Precision: 0.974 / Recall: 0.905\n",
      "Estimators: 5 / Depth: 30 --- Accuracy: 0.956 / Precision: 0.974 / Recall: 0.905\n",
      "Estimators: 5 / Depth: None --- Accuracy: 0.956 / Precision: 0.974 / Recall: 0.905\n",
      "Estimators: 10 / Depth: 5 --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "Estimators: 10 / Depth: 10 --- Accuracy: 0.956 / Precision: 0.974 / Recall: 0.905\n",
      "Estimators: 10 / Depth: 20 --- Accuracy: 0.956 / Precision: 0.974 / Recall: 0.905\n",
      "Estimators: 10 / Depth: 30 --- Accuracy: 0.956 / Precision: 0.974 / Recall: 0.905\n",
      "Estimators: 10 / Depth: None --- Accuracy: 0.956 / Precision: 0.974 / Recall: 0.905\n",
      "Estimators: 20 / Depth: 5 --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "Estimators: 20 / Depth: 10 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 20 / Depth: 20 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 20 / Depth: 30 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 20 / Depth: None --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 50 / Depth: 5 --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "Estimators: 50 / Depth: 10 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 50 / Depth: 20 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 50 / Depth: 30 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 50 / Depth: None --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 100 / Depth: 5 --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "Estimators: 100 / Depth: 10 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 100 / Depth: 20 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 100 / Depth: 30 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Estimators: 100 / Depth: None --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n"
     ]
    }
   ],
   "source": [
    "num_est = [5, 10, 20, 50, 100]\n",
    "max_depths = [5, 10, 20, 30, None]\n",
    "\n",
    "for est in num_est:\n",
    "    for depth in max_depths:\n",
    "        rf = RandomForestClassifier(n_estimators=est, max_depth=depth, random_state=1)\n",
    "        rf.fit(x_train_scaled, y_train)\n",
    "        y_pred = rf.predict(x_test_scaled)\n",
    "\n",
    "        accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "        precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "        recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "        print(f'Estimators: {est} / Depth: {depth} --- Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:29.432452500Z",
     "start_time": "2023-08-01T00:55:27.075134400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:29.437432Z",
     "start_time": "2023-08-01T00:55:29.431944200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty: None / C: 0.0001 --- Accuracy: 0.965 / Precision: 0.952 / Recall: 0.952\n",
      "Penalty: None / C: 0.001 --- Accuracy: 0.965 / Precision: 0.952 / Recall: 0.952\n",
      "Penalty: None / C: 0.01 --- Accuracy: 0.965 / Precision: 0.952 / Recall: 0.952\n",
      "Penalty: None / C: 0.1 --- Accuracy: 0.965 / Precision: 0.952 / Recall: 0.952\n",
      "Penalty: None / C: 1 --- Accuracy: 0.965 / Precision: 0.952 / Recall: 0.952\n",
      "Penalty: None / C: 10 --- Accuracy: 0.965 / Precision: 0.952 / Recall: 0.952\n",
      "Penalty: l2 / C: 0.0001 --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Penalty: l2 / C: 0.001 --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Penalty: l2 / C: 0.01 --- Accuracy: 0.728 / Precision: 1.000 / Recall: 0.262\n",
      "Penalty: l2 / C: 0.1 --- Accuracy: 0.921 / Precision: 1.000 / Recall: 0.786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty: l2 / C: 1 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Penalty: l2 / C: 10 --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n"
     ]
    }
   ],
   "source": [
    "penalties = [None, 'l2']\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "for penalty in penalties:\n",
    "    for c_value in C:\n",
    "        lr = LogisticRegression(penalty=penalty, C=c_value)\n",
    "        lr.fit(x_train_scaled, y_train)\n",
    "        y_pred = lr.predict(x_test_scaled)\n",
    "\n",
    "        accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "        precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "        recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "        print(f'Penalty: {penalty} / C: {c_value} --- Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:29.728003700Z",
     "start_time": "2023-08-01T00:55:29.437432Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:29.748926100Z",
     "start_time": "2023-08-01T00:55:29.681018300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.1 / Kernel: linear --- Accuracy: 0.947 / Precision: 1.000 / Recall: 0.857\n",
      "C: 0.1 / Kernel: poly / Degree: 1 --- Accuracy: 0.947 / Precision: 1.000 / Recall: 0.857\n",
      "C: 0.1 / Kernel: poly / Degree: 2 --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "C: 0.1 / Kernel: poly / Degree: 3 --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 0.1 / Kernel: poly / Degree: 4 --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "C: 0.1 / Kernel: poly / Degree: 5 --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 0.1 / Kernel: rbf --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "C: 0.1 / Kernel: sigmoid --- Accuracy: 0.544 / Precision: 0.000 / Recall: 0.000\n",
      "C: 1 / Kernel: linear --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 1 / Kernel: poly / Degree: 1 --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 1 / Kernel: poly / Degree: 2 --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 1 / Kernel: poly / Degree: 3 --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 1 / Kernel: poly / Degree: 4 --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 1 / Kernel: poly / Degree: 5 --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "C: 1 / Kernel: rbf --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 1 / Kernel: sigmoid --- Accuracy: 0.316 / Precision: 0.050 / Recall: 0.048\n",
      "C: 10 / Kernel: linear --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 10 / Kernel: poly / Degree: 1 --- Accuracy: 0.965 / Precision: 0.975 / Recall: 0.929\n",
      "C: 10 / Kernel: poly / Degree: 2 --- Accuracy: 0.965 / Precision: 0.975 / Recall: 0.929\n",
      "C: 10 / Kernel: poly / Degree: 3 --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "C: 10 / Kernel: poly / Degree: 4 --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "C: 10 / Kernel: poly / Degree: 5 --- Accuracy: 0.947 / Precision: 1.000 / Recall: 0.857\n",
      "C: 10 / Kernel: rbf --- Accuracy: 0.982 / Precision: 1.000 / Recall: 0.952\n",
      "C: 10 / Kernel: sigmoid --- Accuracy: 0.281 / Precision: 0.045 / Recall: 0.048\n"
     ]
    }
   ],
   "source": [
    "C = [0.1, 1, 10]\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "degrees = [1, 2, 3, 4, 5]\n",
    "\n",
    "for c_value in C:\n",
    "    for kernel in kernels:\n",
    "        if kernel == 'poly':\n",
    "            for degree in degrees:\n",
    "                svc = SVC(C=c_value, kernel=kernel, degree=degree)\n",
    "                svc.fit(x_train_scaled, y_train)\n",
    "                y_pred = svc.predict(x_test_scaled)\n",
    "\n",
    "                accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "                precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "                recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "                print(f'C: {c_value} / Kernel: {kernel} / Degree: {degree} --- Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')\n",
    "        else:\n",
    "            svc = SVC(C=c_value, kernel=kernel)\n",
    "            svc.fit(x_train_scaled, y_train)\n",
    "            y_pred = svc.predict(x_test_scaled)\n",
    "\n",
    "            accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "            precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "            recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "            print(f'C: {c_value} / Kernel: {kernel} --- Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:29.947007300Z",
     "start_time": "2023-08-01T00:55:29.686132200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:29.947007300Z",
     "start_time": "2023-08-01T00:55:29.908242200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors: 2 / Weight: uniform --- Accuracy: 0.939 / Precision: 0.973 / Recall: 0.857\n",
      "Neighbors: 2 / Weight: distance --- Accuracy: 0.930 / Precision: 0.925 / Recall: 0.881\n",
      "Neighbors: 3 / Weight: uniform --- Accuracy: 0.930 / Precision: 0.925 / Recall: 0.881\n",
      "Neighbors: 3 / Weight: distance --- Accuracy: 0.930 / Precision: 0.925 / Recall: 0.881\n",
      "Neighbors: 4 / Weight: uniform --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 4 / Weight: distance --- Accuracy: 0.930 / Precision: 0.925 / Recall: 0.881\n",
      "Neighbors: 5 / Weight: uniform --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 5 / Weight: distance --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 6 / Weight: uniform --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 6 / Weight: distance --- Accuracy: 0.939 / Precision: 0.949 / Recall: 0.881\n",
      "Neighbors: 7 / Weight: uniform --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 7 / Weight: distance --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 8 / Weight: uniform --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 8 / Weight: distance --- Accuracy: 0.939 / Precision: 0.949 / Recall: 0.881\n",
      "Neighbors: 9 / Weight: uniform --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 9 / Weight: distance --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 10 / Weight: uniform --- Accuracy: 0.947 / Precision: 1.000 / Recall: 0.857\n",
      "Neighbors: 10 / Weight: distance --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Neighbors: 11 / Weight: uniform --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Neighbors: 11 / Weight: distance --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Neighbors: 12 / Weight: uniform --- Accuracy: 0.947 / Precision: 1.000 / Recall: 0.857\n",
      "Neighbors: 12 / Weight: distance --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Neighbors: 13 / Weight: uniform --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "Neighbors: 13 / Weight: distance --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "Neighbors: 14 / Weight: uniform --- Accuracy: 0.947 / Precision: 1.000 / Recall: 0.857\n",
      "Neighbors: 14 / Weight: distance --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n"
     ]
    }
   ],
   "source": [
    "max_num_neighbors = 14\n",
    "weights = ['uniform', 'distance']\n",
    "\n",
    "for num_neighbor in range(2, max_num_neighbors+1):\n",
    "    for weight in weights:\n",
    "        knn = KNeighborsClassifier(n_neighbors=num_neighbor, weights=weight)\n",
    "        knn.fit(x_train_scaled.values, y_train)\n",
    "        y_pred = knn.predict(x_test_scaled.values)\n",
    "\n",
    "        accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "        precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "        recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "        print(f'Neighbors: {num_neighbor} / Weight: {weight} --- Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:30.375417800Z",
     "start_time": "2023-08-01T00:55:29.931018Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:30.411715300Z",
     "start_time": "2023-08-01T00:55:30.374421800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: identity / Solver: lbfgs --- Accuracy: 0.974 / Precision: 0.953 / Recall: 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: identity / Solver: sgd --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Hidden Layer Size: 10 / Activation: identity / Solver: adam --- Accuracy: 0.974 / Precision: 0.976 / Recall: 0.952\n",
      "Hidden Layer Size: 10 / Activation: logistic / Solver: lbfgs --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: logistic / Solver: sgd --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: logistic / Solver: adam --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Hidden Layer Size: 10 / Activation: tanh / Solver: lbfgs --- Accuracy: 0.965 / Precision: 0.975 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: tanh / Solver: sgd --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: tanh / Solver: adam --- Accuracy: 0.965 / Precision: 0.975 / Recall: 0.929\n",
      "Hidden Layer Size: 10 / Activation: relu / Solver: lbfgs --- Accuracy: 0.965 / Precision: 0.952 / Recall: 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: relu / Solver: sgd --- Accuracy: 0.702 / Precision: 1.000 / Recall: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 10 / Activation: relu / Solver: adam --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 20 / Activation: identity / Solver: lbfgs --- Accuracy: 0.974 / Precision: 0.953 / Recall: 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 20 / Activation: identity / Solver: sgd --- Accuracy: 0.939 / Precision: 0.949 / Recall: 0.881\n",
      "Hidden Layer Size: 20 / Activation: identity / Solver: adam --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "Hidden Layer Size: 20 / Activation: logistic / Solver: lbfgs --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 20 / Activation: logistic / Solver: sgd --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Hidden Layer Size: 20 / Activation: logistic / Solver: adam --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 20 / Activation: tanh / Solver: lbfgs --- Accuracy: 0.982 / Precision: 1.000 / Recall: 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 20 / Activation: tanh / Solver: sgd --- Accuracy: 0.939 / Precision: 0.973 / Recall: 0.857\n",
      "Hidden Layer Size: 20 / Activation: tanh / Solver: adam --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 20 / Activation: relu / Solver: lbfgs --- Accuracy: 0.974 / Precision: 0.976 / Recall: 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 20 / Activation: relu / Solver: sgd --- Accuracy: 0.939 / Precision: 0.973 / Recall: 0.857\n",
      "Hidden Layer Size: 20 / Activation: relu / Solver: adam --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 50 / Activation: identity / Solver: lbfgs --- Accuracy: 0.974 / Precision: 0.953 / Recall: 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 50 / Activation: identity / Solver: sgd --- Accuracy: 0.947 / Precision: 0.974 / Recall: 0.881\n",
      "Hidden Layer Size: 50 / Activation: identity / Solver: adam --- Accuracy: 0.982 / Precision: 1.000 / Recall: 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 50 / Activation: logistic / Solver: lbfgs --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Hidden Layer Size: 50 / Activation: logistic / Solver: sgd --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 50 / Activation: logistic / Solver: adam --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Hidden Layer Size: 50 / Activation: tanh / Solver: lbfgs --- Accuracy: 0.956 / Precision: 0.951 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 50 / Activation: tanh / Solver: sgd --- Accuracy: 0.868 / Precision: 0.886 / Recall: 0.738\n",
      "Hidden Layer Size: 50 / Activation: tanh / Solver: adam --- Accuracy: 0.982 / Precision: 1.000 / Recall: 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 50 / Activation: relu / Solver: lbfgs --- Accuracy: 0.965 / Precision: 0.975 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 50 / Activation: relu / Solver: sgd --- Accuracy: 0.868 / Precision: 0.966 / Recall: 0.667\n",
      "Hidden Layer Size: 50 / Activation: relu / Solver: adam --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100 / Activation: identity / Solver: lbfgs --- Accuracy: 0.974 / Precision: 0.953 / Recall: 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100 / Activation: identity / Solver: sgd --- Accuracy: 0.939 / Precision: 0.949 / Recall: 0.881\n",
      "Hidden Layer Size: 100 / Activation: identity / Solver: adam --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n",
      "Hidden Layer Size: 100 / Activation: logistic / Solver: lbfgs --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100 / Activation: logistic / Solver: sgd --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Hidden Layer Size: 100 / Activation: logistic / Solver: adam --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100 / Activation: tanh / Solver: lbfgs --- Accuracy: 0.965 / Precision: 0.975 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100 / Activation: tanh / Solver: sgd --- Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n",
      "Hidden Layer Size: 100 / Activation: tanh / Solver: adam --- Accuracy: 0.982 / Precision: 1.000 / Recall: 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100 / Activation: relu / Solver: lbfgs --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100 / Activation: relu / Solver: sgd --- Accuracy: 0.886 / Precision: 0.939 / Recall: 0.738\n",
      "Hidden Layer Size: 100 / Activation: relu / Solver: adam --- Accuracy: 0.974 / Precision: 1.000 / Recall: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_layers = [10, 20, 50, 100]\n",
    "activation_functions = ['identity', 'logistic', 'tanh', 'relu']\n",
    "solvers = ['lbfgs', 'sgd', 'adam']\n",
    "for layers in num_layers:\n",
    "    for activation in activation_functions:\n",
    "        for solver in solvers:\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=num_layers, activation=activation, solver=solver)\n",
    "            mlp.fit(x_train_scaled, y_train)\n",
    "            y_pred = mlp.predict(x_test_scaled)\n",
    "\n",
    "            accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "            precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "            recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "            print(f'Hidden Layer Size: {layers} / Activation: {activation} / Solver: {solver} --- Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:46.247351600Z",
     "start_time": "2023-08-01T00:55:30.384012300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from time import perf_counter"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:53:43.161590400Z",
     "start_time": "2023-08-01T14:53:43.159602900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Time: 0.0027461000136099756 / Predict Time: 0.001266500010387972\n",
      "Accuracy: 0.947 / Precision: 0.950 / Recall: 0.905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "\n",
    "start_train = perf_counter()\n",
    "nb.fit(x_train_scaled, y_train)\n",
    "finish_train = perf_counter()\n",
    "\n",
    "start_test = perf_counter()\n",
    "y_pred = nb.predict(x_test_scaled)\n",
    "finish_test = perf_counter()\n",
    "\n",
    "train_time = finish_train - start_train\n",
    "test_time = finish_test - start_test\n",
    "\n",
    "accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "print(f'Train Time: {train_time} / Predict Time: {test_time}')\n",
    "print(f'Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:53:48.088811300Z",
     "start_time": "2023-08-01T14:53:48.067673100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "['saved_objects/nb.pkl']"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(nb, 'saved_objects/nb.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T13:23:44.430233500Z",
     "start_time": "2023-08-01T13:23:44.412835300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=['M', 'B'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['M', 'B'])\n",
    "disp.plot()\n",
    "# plt.show()\n",
    "plt.savefig('visuals/confusion_matrix/gaussian_nb_confusion_matrix.png')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:48:45.219042100Z",
     "start_time": "2023-08-01T14:48:45.021634300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Time: 0.0031239999807439744 / Predict Time: 0.0009671000007074326\n",
      "Accuracy: 0.956 / Precision: 0.974 / Recall: 0.905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "start_train = perf_counter()\n",
    "qda.fit(x_train_scaled, y_train)\n",
    "finish_train = perf_counter()\n",
    "\n",
    "start_test = perf_counter()\n",
    "y_pred = qda.predict(x_test_scaled)\n",
    "finish_test = perf_counter()\n",
    "\n",
    "train_time = finish_train - start_train\n",
    "test_time = finish_test - start_test\n",
    "\n",
    "accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "print(f'Train Time: {train_time} / Predict Time: {test_time}')\n",
    "print(f'Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:54:00.566346700Z",
     "start_time": "2023-08-01T14:54:00.504010300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "['saved_objects/qda.pkl']"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(qda, 'saved_objects/qda.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T13:23:48.897256900Z",
     "start_time": "2023-08-01T13:23:48.867840900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=['M', 'B'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['M', 'B'])\n",
    "disp.plot()\n",
    "# plt.show()\n",
    "plt.savefig('visuals/confusion_matrix/qda_confusion_matrix.png')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:49:21.419570300Z",
     "start_time": "2023-08-01T14:49:21.234577900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Time: 0.13100040002609603 / Predict Time: 0.0036312000011093915\n",
      "Accuracy: 0.956 / Precision: 1.000 / Recall: 0.881\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "gp = GaussianProcessClassifier()\n",
    "\n",
    "start_train = perf_counter()\n",
    "gp.fit(x_train_scaled, y_train)\n",
    "finish_train = perf_counter()\n",
    "\n",
    "start_test = perf_counter()\n",
    "y_pred = gp.predict(x_test_scaled)\n",
    "finish_test = perf_counter()\n",
    "\n",
    "train_time = finish_train - start_train\n",
    "test_time = finish_test - start_test\n",
    "\n",
    "accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "print(f'Train Time: {train_time} / Predict Time: {test_time}')\n",
    "print(f'Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T14:54:29.357831200Z",
     "start_time": "2023-08-01T14:54:29.215126700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "['saved_objects/gp.pkl']"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gp, 'saved_objects/gp.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T13:23:52.700799900Z",
     "start_time": "2023-08-01T13:23:52.656252500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=['M', 'B'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['M', 'B'])\n",
    "disp.plot()\n",
    "# plt.show()\n",
    "plt.savefig('visuals/confusion_matrix/gaussian_process_confusion_matrix.png')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T13:23:53.370008700Z",
     "start_time": "2023-08-01T13:23:53.161778200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T00:55:46.411683600Z",
     "start_time": "2023-08-01T00:55:46.407684500Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
