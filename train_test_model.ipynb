{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-28T17:42:03.040083700Z",
     "start_time": "2023-07-28T17:42:03.022084100Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0         M        17.99         10.38          122.80     1001.0   \n1         M        20.57         17.77          132.90     1326.0   \n2         M        19.69         21.25          130.00     1203.0   \n3         M        11.42         20.38           77.58      386.1   \n4         M        20.29         14.34          135.10     1297.0   \n\n   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0          0.11840           0.27760          0.3001              0.14710   \n1          0.08474           0.07864          0.0869              0.07017   \n2          0.10960           0.15990          0.1974              0.12790   \n3          0.14250           0.28390          0.2414              0.10520   \n4          0.10030           0.13280          0.1980              0.10430   \n\n   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n0         0.2419  ...         25.38          17.33           184.60   \n1         0.1812  ...         24.99          23.41           158.80   \n2         0.2069  ...         23.57          25.53           152.50   \n3         0.2597  ...         14.91          26.50            98.87   \n4         0.1809  ...         22.54          16.67           152.20   \n\n   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n0      2019.0            0.1622             0.6656           0.7119   \n1      1956.0            0.1238             0.1866           0.2416   \n2      1709.0            0.1444             0.4245           0.4504   \n3       567.7            0.2098             0.8663           0.6869   \n4      1575.0            0.1374             0.2050           0.4000   \n\n   concave points_worst  symmetry_worst  fractal_dimension_worst  \n0                0.2654          0.4601                  0.11890  \n1                0.1860          0.2750                  0.08902  \n2                0.2430          0.3613                  0.08758  \n3                0.2575          0.6638                  0.17300  \n4                0.1625          0.2364                  0.07678  \n\n[5 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>...</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/cleaned_data.csv')\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-28T17:42:03.079173400Z",
     "start_time": "2023-07-28T17:42:03.027088400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "x = data.drop(['diagnosis'], axis=1)\n",
    "y = data['diagnosis']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-28T17:42:03.080174600Z",
     "start_time": "2023-07-28T17:42:03.053095500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-28T17:42:03.080174600Z",
     "start_time": "2023-07-28T17:42:03.067476900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "((398, 30), (171, 30), (398,), (171,))"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-28T17:42:03.080751800Z",
     "start_time": "2023-07-28T17:42:03.073985800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from pickle import load"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-28T17:42:03.090112600Z",
     "start_time": "2023-07-28T17:42:03.080751800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "min_max_scaler = load(open('saved_objects/scaler.pkl', 'rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-28T17:42:03.091113400Z",
     "start_time": "2023-07-28T17:42:03.086778800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n0       0.214823      0.176530        0.207864   0.111474         0.439379   \n1       0.287236      0.324653        0.268261   0.162757         0.252505   \n2       0.341663      0.365911        0.335982   0.201442         0.331137   \n3       0.240854      0.126141        0.235229   0.127975         0.517920   \n4       0.219083      0.213392        0.218851   0.112280         0.507087   \n..           ...           ...             ...        ...              ...   \n393     0.606228      0.521136        0.598507   0.444751         0.441184   \n394     0.178380      0.177883        0.169097   0.089841         0.228401   \n395     0.483648      0.500845        0.486559   0.333362         0.491740   \n396     0.333617      0.390260        0.317877   0.195080         0.343685   \n397     0.286289      0.294555        0.268261   0.161315         0.335831   \n\n     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n0            0.219587        0.101406             0.145577       0.415657   \n1            0.069243        0.001621             0.020711       0.383333   \n2            0.341987        0.118627             0.151988       0.225253   \n3            0.264514        0.088590             0.139066       0.301515   \n4            0.364432        0.166284             0.223509       0.417172   \n..                ...             ...                  ...            ...   \n393          0.521921        0.596298             0.571074       0.576768   \n394          0.119744        0.052741             0.039140       0.171212   \n395          0.612075        0.396439             0.394831       0.437879   \n396          0.187304        0.034255             0.094235       0.230808   \n397          0.068382        0.060028             0.145278       0.205556   \n\n     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n0                  0.251373  ...      0.167912       0.244403   \n1                  0.104812  ...      0.224120       0.272655   \n2                  0.216436  ...      0.303095       0.406183   \n3                  0.348055  ...      0.196371       0.099947   \n4                  0.284773  ...      0.167556       0.203891   \n..                      ...  ...           ...            ...   \n393                0.239288  ...      0.522946       0.574627   \n394                0.145902  ...      0.143010       0.231876   \n395                0.321468  ...      0.547492       0.581023   \n396                0.178203  ...      0.263252       0.486674   \n397                0.184355  ...      0.191035       0.287580   \n\n     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n0           0.151751    0.075354          0.447269           0.143761   \n1           0.198366    0.107870          0.204253           0.038018   \n2           0.307236    0.158106          0.291422           0.346592   \n3           0.181832    0.089633          0.534438           0.149252   \n4           0.156980    0.071397          0.464439           0.208333   \n..               ...         ...               ...                ...   \n393         0.489516    0.345016          0.371987           0.394033   \n394         0.136361    0.062918          0.240573           0.104337   \n395         0.503959    0.367627          0.576702           0.782014   \n396         0.238358    0.130333          0.379912           0.136183   \n397         0.169580    0.088650          0.170640           0.020755   \n\n     concavity_worst  concave points_worst  symmetry_worst  \\\n0           0.187760              0.330172        0.275050   \n1           0.001920              0.038179        0.218687   \n2           0.261449              0.460137        0.242485   \n3           0.168818              0.254055        0.304359   \n4           0.239592              0.379725        0.305862   \n..               ...                   ...             ...   \n393         0.590445              0.595189        0.435621   \n394         0.101530              0.117285        0.183868   \n395         0.683389              0.652577        0.437625   \n396         0.064852              0.273643        0.165331   \n397         0.050302              0.172268        0.105461   \n\n     fractal_dimension_worst  \n0                   0.244994  \n1                   0.082236  \n2                   0.250241  \n3                   0.271014  \n4                   0.204090  \n..                       ...  \n393                 0.315237  \n394                 0.133633  \n395                 0.842596  \n396                 0.224435  \n397                 0.069386  \n\n[398 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>fractal_dimension_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.214823</td>\n      <td>0.176530</td>\n      <td>0.207864</td>\n      <td>0.111474</td>\n      <td>0.439379</td>\n      <td>0.219587</td>\n      <td>0.101406</td>\n      <td>0.145577</td>\n      <td>0.415657</td>\n      <td>0.251373</td>\n      <td>...</td>\n      <td>0.167912</td>\n      <td>0.244403</td>\n      <td>0.151751</td>\n      <td>0.075354</td>\n      <td>0.447269</td>\n      <td>0.143761</td>\n      <td>0.187760</td>\n      <td>0.330172</td>\n      <td>0.275050</td>\n      <td>0.244994</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.287236</td>\n      <td>0.324653</td>\n      <td>0.268261</td>\n      <td>0.162757</td>\n      <td>0.252505</td>\n      <td>0.069243</td>\n      <td>0.001621</td>\n      <td>0.020711</td>\n      <td>0.383333</td>\n      <td>0.104812</td>\n      <td>...</td>\n      <td>0.224120</td>\n      <td>0.272655</td>\n      <td>0.198366</td>\n      <td>0.107870</td>\n      <td>0.204253</td>\n      <td>0.038018</td>\n      <td>0.001920</td>\n      <td>0.038179</td>\n      <td>0.218687</td>\n      <td>0.082236</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.341663</td>\n      <td>0.365911</td>\n      <td>0.335982</td>\n      <td>0.201442</td>\n      <td>0.331137</td>\n      <td>0.341987</td>\n      <td>0.118627</td>\n      <td>0.151988</td>\n      <td>0.225253</td>\n      <td>0.216436</td>\n      <td>...</td>\n      <td>0.303095</td>\n      <td>0.406183</td>\n      <td>0.307236</td>\n      <td>0.158106</td>\n      <td>0.291422</td>\n      <td>0.346592</td>\n      <td>0.261449</td>\n      <td>0.460137</td>\n      <td>0.242485</td>\n      <td>0.250241</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.240854</td>\n      <td>0.126141</td>\n      <td>0.235229</td>\n      <td>0.127975</td>\n      <td>0.517920</td>\n      <td>0.264514</td>\n      <td>0.088590</td>\n      <td>0.139066</td>\n      <td>0.301515</td>\n      <td>0.348055</td>\n      <td>...</td>\n      <td>0.196371</td>\n      <td>0.099947</td>\n      <td>0.181832</td>\n      <td>0.089633</td>\n      <td>0.534438</td>\n      <td>0.149252</td>\n      <td>0.168818</td>\n      <td>0.254055</td>\n      <td>0.304359</td>\n      <td>0.271014</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.219083</td>\n      <td>0.213392</td>\n      <td>0.218851</td>\n      <td>0.112280</td>\n      <td>0.507087</td>\n      <td>0.364432</td>\n      <td>0.166284</td>\n      <td>0.223509</td>\n      <td>0.417172</td>\n      <td>0.284773</td>\n      <td>...</td>\n      <td>0.167556</td>\n      <td>0.203891</td>\n      <td>0.156980</td>\n      <td>0.071397</td>\n      <td>0.464439</td>\n      <td>0.208333</td>\n      <td>0.239592</td>\n      <td>0.379725</td>\n      <td>0.305862</td>\n      <td>0.204090</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>393</th>\n      <td>0.606228</td>\n      <td>0.521136</td>\n      <td>0.598507</td>\n      <td>0.444751</td>\n      <td>0.441184</td>\n      <td>0.521921</td>\n      <td>0.596298</td>\n      <td>0.571074</td>\n      <td>0.576768</td>\n      <td>0.239288</td>\n      <td>...</td>\n      <td>0.522946</td>\n      <td>0.574627</td>\n      <td>0.489516</td>\n      <td>0.345016</td>\n      <td>0.371987</td>\n      <td>0.394033</td>\n      <td>0.590445</td>\n      <td>0.595189</td>\n      <td>0.435621</td>\n      <td>0.315237</td>\n    </tr>\n    <tr>\n      <th>394</th>\n      <td>0.178380</td>\n      <td>0.177883</td>\n      <td>0.169097</td>\n      <td>0.089841</td>\n      <td>0.228401</td>\n      <td>0.119744</td>\n      <td>0.052741</td>\n      <td>0.039140</td>\n      <td>0.171212</td>\n      <td>0.145902</td>\n      <td>...</td>\n      <td>0.143010</td>\n      <td>0.231876</td>\n      <td>0.136361</td>\n      <td>0.062918</td>\n      <td>0.240573</td>\n      <td>0.104337</td>\n      <td>0.101530</td>\n      <td>0.117285</td>\n      <td>0.183868</td>\n      <td>0.133633</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>0.483648</td>\n      <td>0.500845</td>\n      <td>0.486559</td>\n      <td>0.333362</td>\n      <td>0.491740</td>\n      <td>0.612075</td>\n      <td>0.396439</td>\n      <td>0.394831</td>\n      <td>0.437879</td>\n      <td>0.321468</td>\n      <td>...</td>\n      <td>0.547492</td>\n      <td>0.581023</td>\n      <td>0.503959</td>\n      <td>0.367627</td>\n      <td>0.576702</td>\n      <td>0.782014</td>\n      <td>0.683389</td>\n      <td>0.652577</td>\n      <td>0.437625</td>\n      <td>0.842596</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>0.333617</td>\n      <td>0.390260</td>\n      <td>0.317877</td>\n      <td>0.195080</td>\n      <td>0.343685</td>\n      <td>0.187304</td>\n      <td>0.034255</td>\n      <td>0.094235</td>\n      <td>0.230808</td>\n      <td>0.178203</td>\n      <td>...</td>\n      <td>0.263252</td>\n      <td>0.486674</td>\n      <td>0.238358</td>\n      <td>0.130333</td>\n      <td>0.379912</td>\n      <td>0.136183</td>\n      <td>0.064852</td>\n      <td>0.273643</td>\n      <td>0.165331</td>\n      <td>0.224435</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>0.286289</td>\n      <td>0.294555</td>\n      <td>0.268261</td>\n      <td>0.161315</td>\n      <td>0.335831</td>\n      <td>0.068382</td>\n      <td>0.060028</td>\n      <td>0.145278</td>\n      <td>0.205556</td>\n      <td>0.184355</td>\n      <td>...</td>\n      <td>0.191035</td>\n      <td>0.287580</td>\n      <td>0.169580</td>\n      <td>0.088650</td>\n      <td>0.170640</td>\n      <td>0.020755</td>\n      <td>0.050302</td>\n      <td>0.172268</td>\n      <td>0.105461</td>\n      <td>0.069386</td>\n    </tr>\n  </tbody>\n</table>\n<p>398 rows Ã— 30 columns</p>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_columns = x.columns\n",
    "x_train_scaled = min_max_scaler.transform(x_train)\n",
    "x_train_scaled = pd.DataFrame(x_train_scaled, columns=x_train_columns)\n",
    "x_train_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-28T17:42:03.111355900Z",
     "start_time": "2023-07-28T17:42:03.091113400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n0       0.358390      0.153649        0.372907   0.233555         0.469146   \n1       0.280557      0.353393        0.281400   0.175130         0.640259   \n2       0.269292      0.240717        0.260167   0.165080         0.434115   \n3       0.543755      0.349979        0.525269   0.418638         0.237133   \n4       0.380921      0.829279        0.361618   0.264041         0.201024   \n..           ...           ...             ...        ...              ...   \n166     0.540683      0.409731        0.532745   0.418157         0.355026   \n167     0.601618      0.360222        0.596292   0.479227         0.547292   \n168     0.414205      0.320529        0.413128   0.293614         0.388305   \n169     0.265195      0.248826        0.254486   0.164359         0.349906   \n170     0.177633      0.470764        0.169034   0.100933         0.451630   \n\n     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n0            0.485107        0.386255             0.335463       0.467878   \n1            0.292579        0.326585             0.390841       0.495133   \n2            0.153609        0.163958             0.179446       0.236859   \n3            0.170316        0.217608             0.309585       0.166126   \n4            0.047384        0.124827             0.145847       0.316029   \n..                ...             ...                  ...            ...   \n166          0.247709        0.300213             0.394036       0.278391   \n167          0.361634        0.600959             0.635783       0.297210   \n168          0.311991        0.265157             0.351757       0.309539   \n169          0.098746        0.103889             0.085996       0.418559   \n170          0.091077        0.023855             0.057295       0.162232   \n\n     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n0                  0.507582  ...      0.318386       0.144806   \n1                  0.375105  ...      0.286065       0.480937   \n2                  0.310447  ...      0.207103       0.200420   \n3                  0.090354  ...      0.516815       0.425324   \n4                  0.062763  ...      0.351117       0.794334   \n..                      ...  ...           ...            ...   \n166                0.157119  ...      0.581049       0.470794   \n167                0.235678  ...      0.625235       0.566282   \n168                0.228728  ...      0.480403       0.457503   \n169                0.162805  ...      0.213649       0.330185   \n170                0.241786  ...      0.150642       0.514865   \n\n     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n0           0.358427    0.195696          0.356054           0.310115   \n1           0.290482    0.179054          0.744388           0.362862   \n2           0.206362    0.120906          0.496149           0.154457   \n3           0.509350    0.396471          0.292151           0.191906   \n4           0.334376    0.236533          0.221694           0.047035   \n..               ...         ...               ...                ...   \n166         0.593530    0.461970          0.462559           0.204919   \n167         0.597739    0.506750          0.521547           0.319056   \n168         0.493115    0.359377          0.424873           0.506203   \n169         0.209128    0.124950          0.310175           0.128629   \n170         0.148939    0.078332          0.331476           0.059095   \n\n     concavity_worst  concave points_worst  symmetry_worst  \\\n0           0.257109              0.412202        0.248768   \n1           0.399840              0.776786        0.460280   \n2           0.178994              0.392857        0.357776   \n3           0.282588              0.584449        0.323477   \n4           0.123562              0.244606        0.328800   \n..               ...                   ...             ...   \n166         0.302236              0.718750        0.295289   \n167         0.474121              0.766369        0.335305   \n168         0.316693              0.673363        0.438991   \n169         0.159105              0.215030        0.401932   \n170         0.028610              0.160193        0.278139   \n\n     fractal_dimension_worst  \n0                   0.242949  \n1                   0.412305  \n2                   0.267611  \n3                   0.094057  \n4                   0.043356  \n..                       ...  \n166                 0.187853  \n167                 0.229896  \n168                 0.326381  \n169                 0.102191  \n170                 0.106192  \n\n[171 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>fractal_dimension_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.358390</td>\n      <td>0.153649</td>\n      <td>0.372907</td>\n      <td>0.233555</td>\n      <td>0.469146</td>\n      <td>0.485107</td>\n      <td>0.386255</td>\n      <td>0.335463</td>\n      <td>0.467878</td>\n      <td>0.507582</td>\n      <td>...</td>\n      <td>0.318386</td>\n      <td>0.144806</td>\n      <td>0.358427</td>\n      <td>0.195696</td>\n      <td>0.356054</td>\n      <td>0.310115</td>\n      <td>0.257109</td>\n      <td>0.412202</td>\n      <td>0.248768</td>\n      <td>0.242949</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.280557</td>\n      <td>0.353393</td>\n      <td>0.281400</td>\n      <td>0.175130</td>\n      <td>0.640259</td>\n      <td>0.292579</td>\n      <td>0.326585</td>\n      <td>0.390841</td>\n      <td>0.495133</td>\n      <td>0.375105</td>\n      <td>...</td>\n      <td>0.286065</td>\n      <td>0.480937</td>\n      <td>0.290482</td>\n      <td>0.179054</td>\n      <td>0.744388</td>\n      <td>0.362862</td>\n      <td>0.399840</td>\n      <td>0.776786</td>\n      <td>0.460280</td>\n      <td>0.412305</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.269292</td>\n      <td>0.240717</td>\n      <td>0.260167</td>\n      <td>0.165080</td>\n      <td>0.434115</td>\n      <td>0.153609</td>\n      <td>0.163958</td>\n      <td>0.179446</td>\n      <td>0.236859</td>\n      <td>0.310447</td>\n      <td>...</td>\n      <td>0.207103</td>\n      <td>0.200420</td>\n      <td>0.206362</td>\n      <td>0.120906</td>\n      <td>0.496149</td>\n      <td>0.154457</td>\n      <td>0.178994</td>\n      <td>0.392857</td>\n      <td>0.357776</td>\n      <td>0.267611</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.543755</td>\n      <td>0.349979</td>\n      <td>0.525269</td>\n      <td>0.418638</td>\n      <td>0.237133</td>\n      <td>0.170316</td>\n      <td>0.217608</td>\n      <td>0.309585</td>\n      <td>0.166126</td>\n      <td>0.090354</td>\n      <td>...</td>\n      <td>0.516815</td>\n      <td>0.425324</td>\n      <td>0.509350</td>\n      <td>0.396471</td>\n      <td>0.292151</td>\n      <td>0.191906</td>\n      <td>0.282588</td>\n      <td>0.584449</td>\n      <td>0.323477</td>\n      <td>0.094057</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.380921</td>\n      <td>0.829279</td>\n      <td>0.361618</td>\n      <td>0.264041</td>\n      <td>0.201024</td>\n      <td>0.047384</td>\n      <td>0.124827</td>\n      <td>0.145847</td>\n      <td>0.316029</td>\n      <td>0.062763</td>\n      <td>...</td>\n      <td>0.351117</td>\n      <td>0.794334</td>\n      <td>0.334376</td>\n      <td>0.236533</td>\n      <td>0.221694</td>\n      <td>0.047035</td>\n      <td>0.123562</td>\n      <td>0.244606</td>\n      <td>0.328800</td>\n      <td>0.043356</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>166</th>\n      <td>0.540683</td>\n      <td>0.409731</td>\n      <td>0.532745</td>\n      <td>0.418157</td>\n      <td>0.355026</td>\n      <td>0.247709</td>\n      <td>0.300213</td>\n      <td>0.394036</td>\n      <td>0.278391</td>\n      <td>0.157119</td>\n      <td>...</td>\n      <td>0.581049</td>\n      <td>0.470794</td>\n      <td>0.593530</td>\n      <td>0.461970</td>\n      <td>0.462559</td>\n      <td>0.204919</td>\n      <td>0.302236</td>\n      <td>0.718750</td>\n      <td>0.295289</td>\n      <td>0.187853</td>\n    </tr>\n    <tr>\n      <th>167</th>\n      <td>0.601618</td>\n      <td>0.360222</td>\n      <td>0.596292</td>\n      <td>0.479227</td>\n      <td>0.547292</td>\n      <td>0.361634</td>\n      <td>0.600959</td>\n      <td>0.635783</td>\n      <td>0.297210</td>\n      <td>0.235678</td>\n      <td>...</td>\n      <td>0.625235</td>\n      <td>0.566282</td>\n      <td>0.597739</td>\n      <td>0.506750</td>\n      <td>0.521547</td>\n      <td>0.319056</td>\n      <td>0.474121</td>\n      <td>0.766369</td>\n      <td>0.335305</td>\n      <td>0.229896</td>\n    </tr>\n    <tr>\n      <th>168</th>\n      <td>0.414205</td>\n      <td>0.320529</td>\n      <td>0.413128</td>\n      <td>0.293614</td>\n      <td>0.388305</td>\n      <td>0.311991</td>\n      <td>0.265157</td>\n      <td>0.351757</td>\n      <td>0.309539</td>\n      <td>0.228728</td>\n      <td>...</td>\n      <td>0.480403</td>\n      <td>0.457503</td>\n      <td>0.493115</td>\n      <td>0.359377</td>\n      <td>0.424873</td>\n      <td>0.506203</td>\n      <td>0.316693</td>\n      <td>0.673363</td>\n      <td>0.438991</td>\n      <td>0.326381</td>\n    </tr>\n    <tr>\n      <th>169</th>\n      <td>0.265195</td>\n      <td>0.248826</td>\n      <td>0.254486</td>\n      <td>0.164359</td>\n      <td>0.349906</td>\n      <td>0.098746</td>\n      <td>0.103889</td>\n      <td>0.085996</td>\n      <td>0.418559</td>\n      <td>0.162805</td>\n      <td>...</td>\n      <td>0.213649</td>\n      <td>0.330185</td>\n      <td>0.209128</td>\n      <td>0.124950</td>\n      <td>0.310175</td>\n      <td>0.128629</td>\n      <td>0.159105</td>\n      <td>0.215030</td>\n      <td>0.401932</td>\n      <td>0.102191</td>\n    </tr>\n    <tr>\n      <th>170</th>\n      <td>0.177633</td>\n      <td>0.470764</td>\n      <td>0.169034</td>\n      <td>0.100933</td>\n      <td>0.451630</td>\n      <td>0.091077</td>\n      <td>0.023855</td>\n      <td>0.057295</td>\n      <td>0.162232</td>\n      <td>0.241786</td>\n      <td>...</td>\n      <td>0.150642</td>\n      <td>0.514865</td>\n      <td>0.148939</td>\n      <td>0.078332</td>\n      <td>0.331476</td>\n      <td>0.059095</td>\n      <td>0.028610</td>\n      <td>0.160193</td>\n      <td>0.278139</td>\n      <td>0.106192</td>\n    </tr>\n  </tbody>\n</table>\n<p>171 rows Ã— 30 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_columns = x.columns\n",
    "x_test_scaled = min_max_scaler.fit_transform(x_test)\n",
    "x_test_scaled = pd.DataFrame(x_test_scaled, columns=x_test_columns)\n",
    "x_test_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-28T17:42:03.198285900Z",
     "start_time": "2023-07-28T17:42:03.112353Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-28T17:42:03.199285600Z",
     "start_time": "2023-07-28T17:42:03.134712800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators: 5 / Depth: 5 --- Accuracy: 0.906 / Precision: 0.851 / Recall: 0.905\n",
      "Estimators: 5 / Depth: 10 --- Accuracy: 0.901 / Precision: 0.829 / Recall: 0.921\n",
      "Estimators: 5 / Depth: 20 --- Accuracy: 0.865 / Precision: 0.763 / Recall: 0.921\n",
      "Estimators: 5 / Depth: 30 --- Accuracy: 0.918 / Precision: 0.915 / Recall: 0.857\n",
      "Estimators: 5 / Depth: None --- Accuracy: 0.924 / Precision: 0.857 / Recall: 0.952\n",
      "Estimators: 10 / Depth: 5 --- Accuracy: 0.877 / Precision: 0.776 / Recall: 0.937\n",
      "Estimators: 10 / Depth: 10 --- Accuracy: 0.942 / Precision: 0.921 / Recall: 0.921\n",
      "Estimators: 10 / Depth: 20 --- Accuracy: 0.883 / Precision: 0.812 / Recall: 0.889\n",
      "Estimators: 10 / Depth: 30 --- Accuracy: 0.883 / Precision: 0.812 / Recall: 0.889\n",
      "Estimators: 10 / Depth: None --- Accuracy: 0.883 / Precision: 0.795 / Recall: 0.921\n",
      "Estimators: 20 / Depth: 5 --- Accuracy: 0.912 / Precision: 0.843 / Recall: 0.937\n",
      "Estimators: 20 / Depth: 10 --- Accuracy: 0.930 / Precision: 0.918 / Recall: 0.889\n",
      "Estimators: 20 / Depth: 20 --- Accuracy: 0.906 / Precision: 0.831 / Recall: 0.937\n",
      "Estimators: 20 / Depth: 30 --- Accuracy: 0.924 / Precision: 0.879 / Recall: 0.921\n",
      "Estimators: 20 / Depth: None --- Accuracy: 0.906 / Precision: 0.831 / Recall: 0.937\n",
      "Estimators: 50 / Depth: 5 --- Accuracy: 0.918 / Precision: 0.866 / Recall: 0.921\n",
      "Estimators: 50 / Depth: 10 --- Accuracy: 0.906 / Precision: 0.841 / Recall: 0.921\n",
      "Estimators: 50 / Depth: 20 --- Accuracy: 0.918 / Precision: 0.845 / Recall: 0.952\n",
      "Estimators: 50 / Depth: 30 --- Accuracy: 0.906 / Precision: 0.841 / Recall: 0.921\n",
      "Estimators: 50 / Depth: None --- Accuracy: 0.918 / Precision: 0.866 / Recall: 0.921\n",
      "Estimators: 100 / Depth: 5 --- Accuracy: 0.924 / Precision: 0.879 / Recall: 0.921\n",
      "Estimators: 100 / Depth: 10 --- Accuracy: 0.918 / Precision: 0.855 / Recall: 0.937\n",
      "Estimators: 100 / Depth: 20 --- Accuracy: 0.912 / Precision: 0.843 / Recall: 0.937\n",
      "Estimators: 100 / Depth: 30 --- Accuracy: 0.918 / Precision: 0.866 / Recall: 0.921\n",
      "Estimators: 100 / Depth: None --- Accuracy: 0.912 / Precision: 0.843 / Recall: 0.937\n"
     ]
    }
   ],
   "source": [
    "num_est = [5, 10, 20, 50, 100]\n",
    "max_depths = [5, 10, 20, 30, None]\n",
    "for est in num_est:\n",
    "    for depth in max_depths:\n",
    "        rf = RandomForestClassifier(n_estimators=est, max_depth=depth)\n",
    "        rf.fit(x_train_scaled, y_train)\n",
    "        y_pred = rf.predict(x_test_scaled)\n",
    "        accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "        precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "        recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "        print(f'Estimators: {est} / Depth: {depth} --- Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-28T17:42:05.253528200Z",
     "start_time": "2023-07-28T17:42:03.138223Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-28T17:42:05.261328700Z",
     "start_time": "2023-07-28T17:42:05.255366800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty: None / C: 0.0001 --- Accuracy: 0.813 / Precision: 0.663 / Recall: 1.000\n",
      "Penalty: None / C: 0.001 --- Accuracy: 0.813 / Precision: 0.663 / Recall: 1.000\n",
      "Penalty: None / C: 0.01 --- Accuracy: 0.813 / Precision: 0.663 / Recall: 1.000\n",
      "Penalty: None / C: 0.1 --- Accuracy: 0.813 / Precision: 0.663 / Recall: 1.000\n",
      "Penalty: None / C: 1 --- Accuracy: 0.813 / Precision: 0.663 / Recall: 1.000\n",
      "Penalty: None / C: 10 --- Accuracy: 0.813 / Precision: 0.663 / Recall: 1.000\n",
      "Penalty: l2 / C: 0.0001 --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Penalty: l2 / C: 0.001 --- Accuracy: 0.632 / Precision: 0.000 / Recall: 0.000\n",
      "Penalty: l2 / C: 0.01 --- Accuracy: 0.772 / Precision: 1.000 / Recall: 0.381\n",
      "Penalty: l2 / C: 0.1 --- Accuracy: 0.965 / Precision: 1.000 / Recall: 0.905\n",
      "Penalty: l2 / C: 1 --- Accuracy: 0.965 / Precision: 0.983 / Recall: 0.921\n",
      "Penalty: l2 / C: 10 --- Accuracy: 0.947 / Precision: 0.897 / Recall: 0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rueip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "penalties = [None, 'l2']\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "for penalty in penalties:\n",
    "    for c_value in C:\n",
    "        lr = LogisticRegression(penalty=penalty, C=c_value)\n",
    "        lr.fit(x_train_scaled, y_train)\n",
    "        y_pred = lr.predict(x_test_scaled)\n",
    "        accuracy = \"%.3f\" % metrics.accuracy_score(y_test, y_pred)\n",
    "        precision = \"%.3f\" % metrics.precision_score(y_test, y_pred, pos_label='M')\n",
    "        recall = \"%.3f\" % metrics.recall_score(y_test, y_pred, pos_label='M')\n",
    "        print(f'Penalty: {penalty} / C: {c_value} --- Accuracy: {accuracy} / Precision: {precision} / Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-28T17:42:05.456615200Z",
     "start_time": "2023-07-28T17:42:05.264212700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-28T17:42:05.459543800Z",
     "start_time": "2023-07-28T17:42:05.458547700Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
